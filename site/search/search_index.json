{"config":{"lang":["pt"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"\\`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#govhubbr","title":"GovHubBr","text":"<p>Voc\u00ea est\u00e1 sendo redirecionado para a landing page...</p> <p>Se isso n\u00e3o acontecer automaticamente, clique aqui.</p>"},{"location":"blog/","title":"Blog","text":"<p>Bem-vindo ao blog do GovHub! Aqui voc\u00ea encontrar\u00e1 as \u00faltimas publica\u00e7\u00f5es, artigos e novidades sobre nossa plataforma de dados p\u00fablicos.</p> <p>Para ver todas as publica\u00e7\u00f5es em formato visual, visite nossa p\u00e1gina de publica\u00e7\u00f5es.</p>"},{"location":"blog/#ultimas-publicacoes","title":"\u00daltimas Publica\u00e7\u00f5es","text":""},{"location":"blog/2024/01/15/govhub-transformando-dados-em-decis%C3%B5es-estrat%C3%A9gicas/","title":"GovHub: Transformando Dados em Decis\u00f5es Estrat\u00e9gicas","text":"<p>O GovHub \u00e9 uma plataforma de software livre desenvolvida para transformar dados brutos em informa\u00e7\u00f5es estrat\u00e9gicas, apoiando gestores p\u00fablicos a tomar decis\u00f5es baseadas em dados.</p>"},{"location":"blog/2024/01/15/govhub-transformando-dados-em-decis%C3%B5es-estrat%C3%A9gicas/#sobre-a-plataforma","title":"Sobre a Plataforma","text":"<p>Nossa plataforma oferece ferramentas avan\u00e7adas para an\u00e1lise e visualiza\u00e7\u00e3o de dados p\u00fablicos, permitindo que \u00f3rg\u00e3os governamentais tomem decis\u00f5es mais informadas e eficazes.</p>"},{"location":"blog/2024/01/15/govhub-transformando-dados-em-decis%C3%B5es-estrat%C3%A9gicas/#principais-funcionalidades","title":"Principais Funcionalidades","text":"<ul> <li>An\u00e1lise de Dados: Ferramentas robustas para processamento e an\u00e1lise</li> <li>Visualiza\u00e7\u00e3o: Dashboards interativos e relat\u00f3rios personalizados  </li> <li>Integra\u00e7\u00e3o: Conecta-se facilmente com diferentes fontes de dados</li> <li>Colabora\u00e7\u00e3o: Permite trabalho em equipe e compartilhamento de insights</li> </ul>"},{"location":"blog/2024/01/15/govhub-transformando-dados-em-decis%C3%B5es-estrat%C3%A9gicas/#como-comecar","title":"Como Come\u00e7ar","text":"<p>Para conhecer mais sobre como implementar o GovHub em seu \u00f3rg\u00e3o, visite nossa documenta\u00e7\u00e3o completa ou entre em contato conosco.</p> <p>Para ver mais publica\u00e7\u00f5es como esta, visite nossa p\u00e1gina de publica\u00e7\u00f5es.</p>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/","title":"Criando Dashboards Eficazes com Apache Superset","text":"<p>O Apache Superset \u00e9 a ferramenta de visualiza\u00e7\u00e3o de dados do GovHub. Aprenda como criar dashboards impactantes para seus dados p\u00fablicos.</p>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#por-que-superset","title":"Por que Superset?","text":"<p>O Apache Superset oferece:</p> <ul> <li>Interface intuitiva para cria\u00e7\u00e3o de gr\u00e1ficos</li> <li>Suporte a m\u00faltiplas fontes de dados</li> <li>Dashboards interativos e responsivos</li> <li>Controle de acesso granular</li> </ul>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#primeiros-passos","title":"Primeiros Passos","text":""},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#1-conectando-fontes-de-dados","title":"1. Conectando Fontes de Dados","text":"<p>No GovHub, o Superset j\u00e1 vem configurado com conex\u00f5es para:</p> <ul> <li>PostgreSQL (dados principais)</li> <li>ClickHouse (dados anal\u00edticos)</li> <li>APIs externas</li> </ul>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#2-criando-seu-primeiro-chart","title":"2. Criando seu Primeiro Chart","text":"<ol> <li>Acesse Charts \u2192 + Chart</li> <li>Selecione sua fonte de dados</li> <li>Escolha o tipo de visualiza\u00e7\u00e3o</li> <li>Configure m\u00e9tricas e dimens\u00f5es</li> </ol>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#3-montando-o-dashboard","title":"3. Montando o Dashboard","text":"<p>Combine m\u00faltiplos charts em um dashboard coeso:</p> <pre><code># Exemplo de configura\u00e7\u00e3o via API\ndashboard_config = {\n    \"dashboard_title\": \"Indicadores Governamentais\",\n    \"charts\": [\n        {\"chart_id\": 1, \"position\": {\"x\": 0, \"y\": 0, \"w\": 6, \"h\": 4}},\n        {\"chart_id\": 2, \"position\": {\"x\": 6, \"y\": 0, \"w\": 6, \"h\": 4}}\n    ]\n}\n</code></pre>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#boas-praticas","title":"Boas Pr\u00e1ticas","text":""},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#design-eficaz","title":"Design Eficaz","text":"<ul> <li>Use cores consistentes com a identidade visual</li> <li>Mantenha layouts limpos e organizados</li> <li>Priorize informa\u00e7\u00f5es mais importantes</li> </ul>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#performance","title":"Performance","text":"<ul> <li>Otimize queries SQL</li> <li>Use agrega\u00e7\u00f5es quando poss\u00edvel</li> <li>Configure cache adequadamente</li> </ul>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#templates-disponiveis","title":"Templates Dispon\u00edveis","text":"<p>O GovHub oferece templates prontos para diferentes casos de uso. Confira nossos dashboards templates para come\u00e7ar rapidamente.</p>"},{"location":"blog/2024/01/05/criando-dashboards-eficazes-com-apache-superset/#tutoriais-relacionados","title":"Tutoriais Relacionados","text":"<ul> <li>Conex\u00f5es no Superset</li> <li>Criando Charts</li> <li>Import/Export de Dashboards</li> </ul> <p>Explore mais conte\u00fados em nossa p\u00e1gina de publica\u00e7\u00f5es.</p>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/","title":"Como Usar DBT no GovHub: Guia Completo","text":"<p>O DBT (Data Build Tool) \u00e9 uma ferramenta essencial para transforma\u00e7\u00e3o de dados no GovHub. Neste tutorial, voc\u00ea aprender\u00e1 como configurar e usar o DBT em sua implementa\u00e7\u00e3o.</p>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#o-que-e-dbt","title":"O que \u00e9 DBT?","text":"<p>O DBT permite que analistas e engenheiros de dados transformem dados em seu warehouse atrav\u00e9s de comandos SELECT simples, organizando o c\u00f3digo de transforma\u00e7\u00e3o em modelos reutiliz\u00e1veis.</p>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#configuracao-inicial","title":"Configura\u00e7\u00e3o Inicial","text":""},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#1-instalacao","title":"1. Instala\u00e7\u00e3o","text":"<pre><code>pip install dbt-core dbt-postgres\n</code></pre>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#2-configuracao-do-projeto","title":"2. Configura\u00e7\u00e3o do Projeto","text":"<p>Crie seu arquivo <code>dbt_project.yml</code>:</p> <pre><code>name: 'govhub_analytics'\nversion: '1.0.0'\nconfig-version: 2\n\nmodel-paths: [\"models\"]\nanalysis-paths: [\"analysis\"]\ntest-paths: [\"tests\"]\nseed-paths: [\"data\"]\nmacro-paths: [\"macros\"]\nsnapshot-paths: [\"snapshots\"]\n</code></pre>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#modelos-e-transformacoes","title":"Modelos e Transforma\u00e7\u00f5es","text":""},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#arquitetura-medallion","title":"Arquitetura Medallion","text":"<p>O GovHub utiliza a arquitetura medallion com tr\u00eas camadas:</p> <ul> <li>Bronze: Dados brutos</li> <li>Silver: Dados limpos e estruturados  </li> <li>Gold: Dados agregados para an\u00e1lise</li> </ul>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#exemplo-de-modelo","title":"Exemplo de Modelo","text":"<pre><code>-- models/silver/dim_orgaos.sql\n{{ config(materialized='table') }}\n\nSELECT \n    codigo_orgao,\n    nome_orgao,\n    sigla_orgao,\n    esfera_governo,\n    created_at,\n    updated_at\nFROM {{ ref('bronze_orgaos') }}\nWHERE status = 'ativo'\n</code></pre>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#testes-e-validacao","title":"Testes e Valida\u00e7\u00e3o","text":"<pre><code>-- tests/assert_orgaos_unicos.sql\nSELECT codigo_orgao, count(*)\nFROM {{ ref('dim_orgaos') }}\nGROUP BY codigo_orgao\nHAVING count(*) &gt; 1\n</code></pre>"},{"location":"blog/2024/01/10/como-usar-dbt-no-govhub-guia-completo/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ul> <li>Explore nossa documenta\u00e7\u00e3o completa sobre DBT</li> <li>Veja exemplos pr\u00e1ticos em nossos templates de dashboard</li> </ul> <p>Para mais tutoriais como este, visite nossa p\u00e1gina de publica\u00e7\u00f5es.</p>"},{"location":"comunidade/dashboards-templates/","title":"Dashboards e Templates","text":"<p>Nesta se\u00e7\u00e3o, apresentamos os modelos de dashboards e os scripts de camada Gold disponibilizados como templates. Esses artefatos servem de ponto de partida para visualiza\u00e7\u00f5es no Apache Superset e para a constru\u00e7\u00e3o de tabelas consolidadas no Data Warehouse.</p>"},{"location":"comunidade/dashboards-templates/#1-scripts-de-camada-gold","title":"1. Scripts de Camada Gold","text":""},{"location":"comunidade/dashboards-templates/#2-exportando-dashboards-do-ipea","title":"2. Exportando Dashboards do IPEA","text":""},{"location":"comunidade/dashboards-templates/#3-importando-e-adaptando-no-seu-superset","title":"3. Importando e Adaptando no Seu Superset","text":""},{"location":"comunidade/dashboards-templates/#4-boas-praticas-de-dashboard","title":"4. Boas Pr\u00e1ticas de Dashboard","text":"<ul> <li>Padroniza\u00e7\u00e3o de cores e estilos: siga o guia de identidade visual do \u00f3rg\u00e3o.</li> <li>Acessibilidade: inclua descri\u00e7\u00f5es em charts e t\u00edtulos claros.</li> <li>Itera\u00e7\u00e3o: revise e colete feedback dos gestores para aprimorar m\u00e9tricas e visualiza\u00e7\u00f5es.</li> </ul>"},{"location":"comunidade/guia-contribuicao/","title":"Guia de Contribui\u00e7\u00e3o","text":"<p>Antes de come\u00e7ar, obrigado por considerar contribuir com o Gov Hub BR. acreditamos que a colabora\u00e7\u00e3o \u00e9 essencial para construir solu\u00e7\u00f5es p\u00fablicas mais eficientes, transparentes e sustent\u00e1veis.</p> <p>o gov hub br \u00e9 um projeto open-source com o prop\u00f3sito de transformar dados p\u00fablicos em ativos estrat\u00e9gicos para a administra\u00e7\u00e3o p\u00fablica e a sociedade. toda contribui\u00e7\u00e3o, seja c\u00f3digo, documenta\u00e7\u00e3o, ideias ou feedback, \u00e9 bem-vinda.</p>"},{"location":"comunidade/guia-contribuicao/#como-contribuir","title":"Como contribuir","text":"<p>1 fa\u00e7a um fork do reposit\u00f3rio</p> <p>Clique em \"fork\" no canto superior direito da p\u00e1gina do projeto e clone o reposit\u00f3rio no seu ambiente local:</p> <pre><code>git clone https://github.com/seu-usuario/govhub-br.git\n</code></pre> <ul> <li>crie uma nova branch</li> </ul> <p>recomendamos criar uma branch com um nome descritivo, como ajuste-na-doc ou feature-nova-transformacao: <pre><code>git checkout -b minha-contribuicao\n</code></pre></p> <p>2 . fa\u00e7a suas altera\u00e7\u00f5es</p> <p>contribui\u00e7\u00f5es podem incluir:</p> <ul> <li> <p>melhorias no c\u00f3digo ou em pipelines de dados</p> </li> <li> <p>ajustes ou acr\u00e9scimos na documenta\u00e7\u00e3o</p> </li> <li> <p>sugest\u00f5es de novas funcionalidades</p> </li> <li> <p>corre\u00e7\u00e3o de erros ou inconsist\u00eancias</p> </li> </ul> <p>teste e valide sua contribui\u00e7\u00e3o</p> <ol> <li>sobre o pull request</li> </ol> <p>Antes de enviar, certifique-se de que sua altera\u00e7\u00e3o est\u00e1 funcionando corretamente, sem quebrar funcionalidades existentes, e que segue os padr\u00f5es definidos pelo projeto.</p> <p>Envie um pull request utilizando o modelo dispon\u00edvel no reposit\u00f3rio. isso ajuda a equipe a entender rapidamente o contexto da sua contribui\u00e7\u00e3o e agiliza o processo de revis\u00e3o.</p> <p>Suba sua branch para o seu fork e abra um pull request direcionado ao reposit\u00f3rio principal. descreva de forma objetiva o que foi alterado, por que essa mudan\u00e7a \u00e9 necess\u00e1ria e, sempre que poss\u00edvel, inclua prints, logs ou links relacionados.</p>"},{"location":"comunidade/guia-contribuicao/#abertura-de-issues","title":"\ud83d\udccc Abertura de Issues","text":"<p>Toda solicita\u00e7\u00e3o de mudan\u00e7a, corre\u00e7\u00e3o de bug ou sugest\u00e3o de melhoria deve ser registrada por meio de uma issue. As issues devem ser abertas utilizando o modelo padr\u00e3o fornecido pelo reposit\u00f3rio, o qual ajuda a manter a clareza, rastreabilidade e organiza\u00e7\u00e3o da discuss\u00e3o. Certifique-se de preencher todos os campos obrigat\u00f3rios com informa\u00e7\u00f5es precisas, como contexto, impacto e poss\u00edveis caminhos de solu\u00e7\u00e3o.</p>"},{"location":"comunidade/guia-contribuicao/#commits","title":"\ud83d\udcdd Commits","text":"<p>As mensagens de commit devem seguir um padr\u00e3o pr\u00e9-definido, inspirado no Conventional Commits, com prefixos como:</p> <ul> <li><code>feat:</code> para novas funcionalidades;</li> <li><code>fix:</code> para corre\u00e7\u00f5es de bugs;</li> <li><code>docs:</code> para altera\u00e7\u00f5es na documenta\u00e7\u00e3o;</li> <li><code>ci:</code> para mudan\u00e7as relacionadas a integra\u00e7\u00e3o cont\u00ednua;</li> <li><code>refactor:</code> para melhorias no c\u00f3digo que n\u00e3o alteram comportamento.</li> </ul> <p>Cada mensagem de commit deve conter uma descri\u00e7\u00e3o clara, objetiva e sucinta da mudan\u00e7a implementada. Quando necess\u00e1rio, utilize a descri\u00e7\u00e3o estendida do commit para detalhar motiva\u00e7\u00f5es, impactos e decis\u00f5es t\u00e9cnicas importantes. Isso facilita o entendimento hist\u00f3rico das mudan\u00e7as e contribui para uma base de c\u00f3digo mais sustent\u00e1vel e audit\u00e1vel.</p>"},{"location":"comunidade/guia-contribuicao/#convivencia-respeito-e-etica-na-colaboracao","title":"\ud83e\udd1d Conviv\u00eancia, respeito e \u00e9tica na colabora\u00e7\u00e3o","text":"<p>A colabora\u00e7\u00e3o neste reposit\u00f3rio deve sempre ocorrer em um ambiente de respeito m\u00fatuo, empatia e abertura ao di\u00e1logo. Espera-se que todas as intera\u00e7\u00f5es \u2014 sejam em issues, pull requests, revis\u00f5es de c\u00f3digo ou discuss\u00f5es t\u00e9cnicas \u2014 sejam conduzidas com educa\u00e7\u00e3o, cordialidade e esp\u00edrito colaborativo. Cr\u00edticas devem ser construtivas, com foco na solu\u00e7\u00e3o e na melhoria cont\u00ednua, nunca direcionadas de forma pessoal.</p> <p>N\u00e3o ser\u00e1 tolerado nenhum tipo de discurso ou comportamento ofensivo, discriminat\u00f3rio, agressivo ou de \u00f3dio. Isso inclui, mas n\u00e3o se limita a: racismo, sexismo, homofobia, xenofobia ou qualquer outra forma de preconceito. A manuten\u00e7\u00e3o de um ambiente saud\u00e1vel, inclusivo e profissional \u00e9 responsabilidade de todos os colaboradores e condi\u00e7\u00e3o essencial para a participa\u00e7\u00e3o neste projeto.</p> <p>Contribuir com respeito \u00e9 t\u00e3o importante quanto contribuir com c\u00f3digo.</p>"},{"location":"comunidade/pre-requisitos/","title":"Pr\u00e9-requisitos para Replica\u00e7\u00e3o do Gov Hub BR","text":"<p>Antes de iniciar o processo de replica\u00e7\u00e3o da plataforma Gov Hub BR em outro \u00f3rg\u00e3o p\u00fablico, \u00e9 importante garantir que alguns pr\u00e9-requisitos t\u00e9cnicos e operacionais estejam atendidos. Esta se\u00e7\u00e3o apresenta os componentes essenciais de infraestrutura, as tecnologias utilizadas no projeto e os conhecimentos recomendados para as equipes envolvidas.</p>"},{"location":"comunidade/pre-requisitos/#requisitos-de-infraestrutura","title":"\ud83e\uddf1 Requisitos de Infraestrutura","text":"<p>A plataforma foi constru\u00edda para funcionar em ambientes locais ou em nuvem, utilizando cont\u00eaineres Docker e K8s para facilitar a instala\u00e7\u00e3o e padronizar ambientes. O ideal \u00e9 contar com servidores dedicados (ou m\u00e1quinas virtuais) organizados por fun\u00e7\u00e3o.</p> <p>Alternativamente, todo o stack pode ser executado com <code>docker-compose</code> em um \u00fanico ambiente para fins de testes ou prototipa\u00e7\u00e3o.</p>"},{"location":"comunidade/pre-requisitos/#tecnologias-utilizadas","title":"\ud83d\udd27 Tecnologias Utilizadas","text":"<p>Abaixo, a lista das tecnologias principais empregadas na arquitetura da plataforma:</p> Tecnologia Fun\u00e7\u00e3o Documenta\u00e7\u00e3o Oficial Apache Airflow Orquestra\u00e7\u00e3o e agendamento de pipelines (DAGs) https://airflow.apache.org/ DBT (Data Build Tool) Transforma\u00e7\u00e3o e modelagem de dados https://docs.getdbt.com/ PostgreSQL Armazenamento relacional e data warehouse https://www.postgresql.org/docs/ Apache Superset Cria\u00e7\u00e3o de dashboards e visualiza\u00e7\u00f5es interativas https://superset.apache.org/ Docker Padroniza\u00e7\u00e3o de ambiente e deploy em containers https://docs.docker.com/ Astronomer Cosmos Integra\u00e7\u00e3o entre DBT e Airflow https://github.com/astronomer/astronomer-cosmos Kubernetes (K8s) Orquestra\u00e7\u00e3o de cont\u00eaineres e escalabilidade https://kubernetes.io/docs/"},{"location":"comunidade/pre-requisitos/#conhecimentos-tecnicos-recomendados","title":"\ud83d\udc68\u200d\ud83d\udcbb Conhecimentos T\u00e9cnicos Recomendados","text":"<p>Embora a plataforma tenha sido pensada para ser reutiliz\u00e1vel, alguns conhecimentos s\u00e3o importantes para facilitar a implanta\u00e7\u00e3o e manuten\u00e7\u00e3o do projeto:</p> <ul> <li>Python (n\u00edvel b\u00e1sico a intermedi\u00e1rio): para leitura e edi\u00e7\u00e3o das DAGs no Airflow.</li> <li>SQL (n\u00edvel intermedi\u00e1rio): para trabalhar com os modelos DBT e an\u00e1lises no Superset.</li> <li>Conceitos de ETL/ELT e modelagem de dados: para adaptar os fluxos \u00e0s regras de neg\u00f3cio do \u00f3rg\u00e3o.</li> <li>Conhecimento b\u00e1sico em APIs REST: para configurar e consumir dados de sistemas estruturantes.</li> </ul>"},{"location":"comunidade/pre-requisitos/#consideracoes-sobre-acesso-a-apis","title":"\ud83d\udd12 Considera\u00e7\u00f5es sobre Acesso a APIs","text":"<p>Nem todas as APIs p\u00fablicas permitem acesso irrestrito. Algumas exigem:</p> <ul> <li>Certificado digital A1/A3 </li> <li>Token de autentica\u00e7\u00e3o gerado por sistemas internos</li> <li>Libera\u00e7\u00e3o espec\u00edfica por parte da equipe respons\u00e1vel pela API</li> </ul> <p>Exemplo pr\u00e1tico: durante os testes com dados do IBAMA, o acesso foi limitado por exig\u00eancia de certificado digital. Portanto, o ideal \u00e9 iniciar com APIs p\u00fablicas e abertas, como as do ComprasGov ou TransfereGov.</p> <p>Com esses pr\u00e9-requisitos atendidos, \u00e9 poss\u00edvel iniciar a implanta\u00e7\u00e3o da estrutura base do Gov Hub BR no \u00f3rg\u00e3o desejado.</p>"},{"location":"documentacao/arquitetura/","title":"Arquitetura da Solu\u00e7\u00e3o","text":"<p>A arquitetura da plataforma Gov Hub BR foi elaborada para promover modularidade, escalabilidade e ado\u00e7\u00e3o de tecnologias de c\u00f3digo aberto, assegurando flexibilidade adaptativa \u00e0s demandas espec\u00edficas de diferentes \u00f3rg\u00e3os p\u00fablicos, sem comprometer os requisitos de governan\u00e7a e qualidade de dados.</p>"},{"location":"documentacao/arquitetura/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O design adota o paradigma Lakehouse, estruturado em tr\u00eas camadas de processamento de dados:</p> <pre><code>Fontes de dados (APIs)\n\u2193\nApache Airflow (orquestra\u00e7\u00e3o e extra\u00e7\u00e3o)\n\u2193\nDBT (transforma\u00e7\u00e3o e modelagem)\n\u2193\nPostgreSQL (armazenamento em Bronze, Silver e Gold)\n\u2193\nApache Superset (visualiza\u00e7\u00e3o e relat\u00f3rios)\n</code></pre>"},{"location":"documentacao/arquitetura/#componentes-principais","title":"Componentes Principais","text":""},{"location":"documentacao/arquitetura/#apache-airflow","title":"Apache Airflow","text":"<p>Disponibiliza orquestra\u00e7\u00e3o robusta de fluxos de trabalho (ETL) por meio de Grafos Ac\u00edclicos Dirigidos (DAGs), coordenando a extra\u00e7\u00e3o automatizada de dados brutos a partir das APIs governamentais, com registro de depend\u00eancias e monitoramento em tempo real.</p>"},{"location":"documentacao/arquitetura/#dbt-data-build-tool","title":"DBT (Data Build Tool)","text":"<p>Respons\u00e1vel pela aplica\u00e7\u00e3o de transforma\u00e7\u00f5es program\u00e1ticas em SQL, modelagem de dados e gera\u00e7\u00e3o de artefatos nas camadas Silver e Gold. Facilita versionamento, testes automatizados e documenta\u00e7\u00e3o cont\u00ednua dos modelos.</p>"},{"location":"documentacao/arquitetura/#astronomer-cosmos","title":"Astronomer Cosmos","text":"<p>Extens\u00e3o que integra nativamente o DBT ao Airflow, habilitando a execu\u00e7\u00e3o orquestrada de modelos DBT dentro das DAGs e simplificando a gest\u00e3o de depend\u00eancias entre tarefas de transforma\u00e7\u00e3o.</p>"},{"location":"documentacao/arquitetura/#postgresql","title":"PostgreSQL","text":"<p>Servi\u00e7o de armazenamento relacional configurado como um Data Warehouse, organizado em tr\u00eas dom\u00ednios:</p> <ul> <li>Bronze: reposit\u00f3rio de dados brutos, sem altera\u00e7\u00f5es.</li> <li>Silver: dados limpos, validados e normalizados para an\u00e1lises explorat\u00f3rias.</li> <li>Gold: dados agregados e estruturados conforme regras de neg\u00f3cio espec\u00edficas.</li> </ul>"},{"location":"documentacao/arquitetura/#apache-superset","title":"Apache Superset","text":"<p>Ferramenta de business intelligence que consome a camada Gold, permitindo a constru\u00e7\u00e3o de pain\u00e9is interativos e relat\u00f3rios anal\u00edticos parametriz\u00e1veis, promovendo a dissemina\u00e7\u00e3o de insights corporativos.</p>"},{"location":"documentacao/arquitetura/#organizacao-em-camadas","title":"Organiza\u00e7\u00e3o em Camadas","text":"<ul> <li>Bronze: preserva\u00e7\u00e3o integral dos registros originais, garantindo auditabilidade.</li> <li>Silver: normaliza\u00e7\u00e3o, enriquecimento e unifica\u00e7\u00e3o de conjuntos de dados.</li> <li>Gold: consolida\u00e7\u00e3o final e aplica\u00e7\u00e3o de l\u00f3gica de neg\u00f3cio para suporte \u00e0 tomada de decis\u00e3o.</li> </ul>"},{"location":"documentacao/arquitetura/#flexibilidade-e-escalabilidade","title":"Flexibilidade e Escalabilidade","text":"<p>A pilha pode ser executada localmente via Docker Compose para valida\u00e7\u00f5es iniciais, e dimensionada para ambientes de produ\u00e7\u00e3o em nuvem, incluindo:</p> <ul> <li>Execu\u00e7\u00e3o distribu\u00edda do Airflow em Kubernetes ou CeleryExecutor.</li> <li>Substitui\u00e7\u00e3o de PostgreSQL por solu\u00e7\u00f5es anal\u00edticas escal\u00e1veis (Redshift, Snowflake, BigQuery).</li> <li>Otimiza\u00e7\u00f5es de cache e materializa\u00e7\u00f5es no Superset para grandes volumes de dados.</li> </ul> <p>Para maior detalhamento do processo de extra\u00e7\u00e3o, transforma\u00e7\u00e3o e carga de dados, consulte a se\u00e7\u00e3o Integra\u00e7\u00e3o de Dados.</p>"},{"location":"documentacao/arquitetura/#configuracao-da-infraestrutura","title":"configura\u00e7\u00e3o da infraestrutura","text":""},{"location":"documentacao/arquitetura/#servidores-e-ambiente","title":"servidores e ambiente","text":"<ul> <li>o projeto pode ser executado localmente com docker-compose ou em ambientes cloud.</li> <li>estrutura recomendada:</li> <li>servidor para orquestra\u00e7\u00e3o (airflow + cosmos)</li> <li>servidor para banco de dados (postgres)</li> <li>servidor para bi (superset)</li> </ul>"},{"location":"documentacao/arquitetura/#permissoes-e-seguranca","title":"permiss\u00f5es e seguran\u00e7a","text":"<ul> <li>acesso ao banco de dados deve ser controlado com usu\u00e1rios distintos para leitura, escrita e administra\u00e7\u00e3o.</li> <li>airflow deve se conectar ao banco com usu\u00e1rio restrito (ex: <code>etl_user</code>).</li> <li>superset deve se conectar com um usu\u00e1rio apenas-leitura.</li> <li>recomenda-se a utiliza\u00e7\u00e3o de <code>.env</code> ou secrets manager para vari\u00e1veis sens\u00edveis.</li> </ul>"},{"location":"documentacao/arquitetura/#conectores","title":"conectores","text":"<ul> <li>airflow e dbt usam conex\u00f5es configur\u00e1veis por URI.</li> <li>exemplo de conex\u00e3o airflow \u2192 postgres:</li> </ul> <p>postgres://etl_user:senha@host:5432/db</p> <ul> <li>superset se conecta ao banco via SQLAlchemy URI configurada na interface web.</li> </ul>"},{"location":"documentacao/arquitetura/#escalabilidade","title":"escalabilidade","text":"<p>o gov hub br foi desenhado para operar com grandes volumes de dados e pode escalar de forma horizontal e modular:</p> <ul> <li>airflow pode ser executado com m\u00faltiplos workers em um ambiente Kubernetes ou Celery.</li> <li>dbt suporta execu\u00e7\u00e3o paralela e pode ser integrado com cloud warehouses altamente escal\u00e1veis.</li> <li>postgres pode ser substitu\u00eddo por solu\u00e7\u00f5es como redshift, snowflake ou bigquery conforme a demanda.</li> <li>dashboards em superset podem ser otimizados com caching e queries materializadas.</li> </ul>"},{"location":"documentacao/arquitetura/#consideracoes-finais","title":"considera\u00e7\u00f5es finais","text":"<p>a arquitetura modular do gov hub br permite flexibilidade para evoluir conforme as necessidades dos \u00f3rg\u00e3os p\u00fablicos, mantendo uma base s\u00f3lida de governan\u00e7a e performance.</p>"},{"location":"documentacao/instalacao/","title":"Instala\u00e7\u00e3o","text":"<p>O Data Pipeline Project \u00e9 uma solu\u00e7\u00e3o moderna que utiliza ferramentas como Airflow, DBT, Jupyter e Superset para orquestra\u00e7\u00e3o, transforma\u00e7\u00e3o, an\u00e1lise e visualiza\u00e7\u00e3o de dados. Este guia ajudar\u00e1 voc\u00ea a come\u00e7ar rapidamente.</p>"},{"location":"documentacao/instalacao/#pre-requisitos","title":"\ud83d\udccb Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de ter os seguintes softwares instalados:</p> <ul> <li>Docker e Docker Compose: Para gerenciamento de cont\u00eaineres.</li> <li>Make: Ferramenta de automa\u00e7\u00e3o de build.</li> <li>Python 3.x: Para execu\u00e7\u00e3o de scripts e desenvolvimento.</li> <li>Git: Controle de vers\u00e3o.</li> </ul> <p>Caso precise de ajuda para instalar esses componentes, consulte a documenta\u00e7\u00e3o oficial de cada ferramenta:</p> <ul> <li>Instala\u00e7\u00e3o do Docker</li> <li>Guia do Python</li> <li>Guia do Git</li> </ul>"},{"location":"documentacao/instalacao/#instalacao_1","title":"\ud83d\ude80 Instala\u00e7\u00e3o","text":""},{"location":"documentacao/instalacao/#1-clonando-o-repositorio","title":"1. Clonando o Reposit\u00f3rio","text":"<p>Para obter o c\u00f3digo-fonte do projeto, clone o reposit\u00f3rio Git:</p> <pre><code>git clone git@gitlab.com:lappis-unb/gest-odadosipea/app-lappis-ipea.git\ncd app-lappis-ipea\n</code></pre>"},{"location":"documentacao/instalacao/#2-configurando-o-ambiente","title":"2. Configurando o Ambiente","text":"<p>Execute o comando abaixo para configurar automaticamente o ambiente de desenvolvimento:</p> <pre><code>make setup\n</code></pre> <p>Este comando ir\u00e1:</p> <ul> <li>Criar ambientes virtuais necess\u00e1rios.</li> <li>Instalar depend\u00eancias do projeto.</li> <li>Configurar hooks de pr\u00e9-commit.</li> <li>Preparar o ambiente de desenvolvimento para execu\u00e7\u00e3o local.</li> </ul> <p>!!! note \"Dica\" Caso encontre problemas durante a configura\u00e7\u00e3o, verifique se o Docker est\u00e1 rodando corretamente e se voc\u00ea possui permiss\u00f5es administrativas no sistema.</p>"},{"location":"documentacao/instalacao/#executando-o-projeto-localmente","title":"\ud83c\udfc3\u200d\u2642\ufe0f Executando o Projeto Localmente","text":"<p>Ap\u00f3s a configura\u00e7\u00e3o, inicialize todos os servi\u00e7os com o Docker Compose:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"documentacao/instalacao/#acessando-os-componentes","title":"Acessando os Componentes","text":"<p>Uma vez que os servi\u00e7os estejam em execu\u00e7\u00e3o, voc\u00ea pode acessar as ferramentas principais nos seguintes URLs:</p> <ul> <li>Airflow: http://localhost:8080</li> <li>Jupyter: http://localhost:8888</li> <li>Superset: http://localhost:8088</li> </ul> <p>Certifique-se de que todas as portas mencionadas estejam dispon\u00edveis no seu ambiente.</p>"},{"location":"documentacao/instalacao/#estrutura-do-projeto","title":"\ud83d\udee0 Estrutura do Projeto","text":"<p>A estrutura do projeto \u00e9 organizada para separar cada componente da stack, facilitando a manuten\u00e7\u00e3o e o desenvolvimento:</p> <pre><code>.\n\u251c\u2500\u2500 airflow/           # Configura\u00e7\u00f5es e DAGs do Airflow\n\u2502   \u251c\u2500\u2500 dags/          # Defini\u00e7\u00e3o de workflows\n\u2502   \u2514\u2500\u2500 plugins/       # Plugins personalizados\n\u251c\u2500\u2500 dbt/               # Modelos e configura\u00e7\u00f5es do dbt\n\u2502   \u2514\u2500\u2500 models/        # Modelagem de dados\n\u251c\u2500\u2500 jupyter/           # Notebooks interativos\n\u2502   \u2514\u2500\u2500 notebooks/     # An\u00e1lises explorat\u00f3rias\n\u251c\u2500\u2500 superset/          # Dashboards e visualiza\u00e7\u00f5es\n\u2502   \u2514\u2500\u2500 dashboards/    # Configura\u00e7\u00f5es de dashboards\n\u251c\u2500\u2500 docker-compose.yml # Configura\u00e7\u00e3o do Docker Compose\n\u251c\u2500\u2500 Makefile           # Comandos automatizados\n\u2514\u2500\u2500 README.md          # Documenta\u00e7\u00e3o inicial\n</code></pre> <p>Essa organiza\u00e7\u00e3o modular permite que cada componente seja desenvolvido e mantido de forma independente.</p>"},{"location":"documentacao/instalacao/#comandos-uteis-no-makefile","title":"\ud83c\udfaf Comandos \u00dateis no Makefile","text":"<p>O Makefile facilita a execu\u00e7\u00e3o de tarefas repetitivas e a configura\u00e7\u00e3o do ambiente. Aqui est\u00e3o os principais comandos dispon\u00edveis:</p> <ul> <li><code>make setup</code>: Configura\u00e7\u00e3o inicial do projeto, incluindo instala\u00e7\u00e3o de depend\u00eancias e configura\u00e7\u00e3o do ambiente.</li> <li><code>make lint</code>: Verifica\u00e7\u00e3o de qualidade do c\u00f3digo com ferramentas de linting.</li> <li><code>make tests</code>: Execu\u00e7\u00e3o da su\u00edte de testes para validar mudan\u00e7as no c\u00f3digo.</li> <li><code>make clean</code>: Remo\u00e7\u00e3o de arquivos gerados automaticamente.</li> <li><code>make build</code>: Cria\u00e7\u00e3o de imagens Docker para o ambiente de desenvolvimento.</li> </ul>"},{"location":"documentacao/instalacao/#fluxo-de-trabalho-com-git","title":"\ud83d\udd10 Fluxo de Trabalho com Git","text":"<p>Este projeto utiliza commits assinados digitalmente (GPG signing) como parte do fluxo de trabalho. Siga os passos abaixo para configurar:</p> <ol> <li>Gere uma chave GPG:</li> </ol> <pre><code>  gpg --full-generate-key\n</code></pre> <ol> <li> <p>Configure o Git para usar sua chave GPG: <pre><code>  git config --global user.signingkey YOUR_KEY_ID\n  git config --global commit.gpgsign true\n</code></pre></p> </li> <li> <p>Adicione sua chave GPG \u00e0 sua conta do GitLab:</p> </li> <li>Acesse as configura\u00e7\u00f5es da sua conta GitLab.</li> <li>Cole a chave p\u00fablica gerada pelo comando:</li> </ol> <pre><code>gpg --armor --export YOUR_KEY_ID\n</code></pre> <p>Com isso, todos os seus commits estar\u00e3o assinados e prontos para serem utilizados no projeto.</p>"},{"location":"documentacao/instalacao/#documentacao-util","title":"\ud83d\udcda Documenta\u00e7\u00e3o \u00datil","text":"<p>Para aproveitar ao m\u00e1ximo os componentes do projeto, consulte as documenta\u00e7\u00f5es oficiais:</p> <ul> <li>Documenta\u00e7\u00e3o do Airflow</li> <li>Documenta\u00e7\u00e3o do DBT</li> <li>Documenta\u00e7\u00e3o do Superset</li> </ul>"},{"location":"documentacao/tutoriais/dbt/arquitetura-medallion/","title":"Arquitetura e Modelagem de Dados","text":"<p>A modelagem de dados e a organiza\u00e7\u00e3o dos esquemas devem seguir a arquitetura em camadas definida para o reposit\u00f3rio, baseada nos est\u00e1gios de maturidade e tratamento dos dados. Esta abordagem facilita a rastreabilidade, o controle de qualidade e a evolu\u00e7\u00e3o gradual dos dados ao longo do tempo. As camadas est\u00e3o estruturadas da seguinte forma:</p> <ul> <li>Raw: camada bruta, que armazena os dados exatamente como foram recebidos da fonte, sem qualquer transforma\u00e7\u00e3o. Serve como fonte de verdade e hist\u00f3rico imut\u00e1vel.</li> <li>Bronze: camada de dados limpos e estruturados de forma padronizada, com corre\u00e7\u00f5es m\u00ednimas (como tipos de dados e normaliza\u00e7\u00e3o b\u00e1sica), mantendo a granularidade original.</li> <li>Silver: camada onde os dados passam por enriquecimentos, jun\u00e7\u00f5es e integra\u00e7\u00f5es entre diferentes fontes, al\u00e9m de valida\u00e7\u00f5es mais complexas.</li> <li>Gold: camada final, otimizada para consumo e an\u00e1lise. Cont\u00e9m m\u00e9tricas, agrega\u00e7\u00f5es e tabelas derivadas voltadas a casos de uso espec\u00edficos, como dashboards, relat\u00f3rios e servi\u00e7os.</li> </ul> <p>Ao propor modifica\u00e7\u00f5es ou novos pipelines, certifique-se de posicionar corretamente os dados dentro dessa estrutura e seguir os padr\u00f5es de nomenclatura, versionamento e particionamento definidos. Altera\u00e7\u00f5es em qualquer uma dessas camadas devem ser devidamente documentadas e revisadas pelo time respons\u00e1vel, garantindo consist\u00eancia e rastreabilidade.</p> <p>Essa organiza\u00e7\u00e3o em camadas \u00e9 fundamental para garantir qualidade, confiabilidade e governan\u00e7a sobre os dados tratados no reposit\u00f3rio.</p>"},{"location":"documentacao/tutoriais/dbt/cosmos/","title":"Usando Astronomer Cosmos para Orquestra\u00e7\u00e3o de Modelos no dbt","text":""},{"location":"documentacao/tutoriais/dbt/cosmos/#o-que-e-o-astronomer-cosmos","title":"O que \u00e9 o Astronomer Cosmos?","text":"<p>Astronomer Cosmos \u00e9 uma biblioteca que integra o dbt com o Apache Airflow, permitindo orquestrar pipelines de dados definidos em dbt diretamente como DAGs no Airflow.</p>"},{"location":"documentacao/tutoriais/dbt/cosmos/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ul> <li>Projeto dbt configurado</li> <li>Ambiente com Airflow instalado</li> <li>Instala\u00e7\u00e3o do pacote <code>astronomer-cosmos</code></li> </ul> <pre><code>pip install astronomer-cosmos\n</code></pre>"},{"location":"documentacao/tutoriais/dbt/cosmos/#configurando-o-cosmos","title":"Configurando o Cosmos","text":"<ol> <li> <p>Adicione seu projeto dbt ao reposit\u00f3rio do Airflow     Certifique-se de que o diret\u00f3rio do projeto dbt esteja acess\u00edvel pelo Airflow.</p> </li> <li> <p>Crie uma DAG usando Cosmos</p> </li> </ol> <p>Exemplo de DAG:</p> <pre><code>from cosmos.profiles import PostgresUserPasswordProfileMapping\nfrom cosmos.providers.dbt.core.operators import DbtRunOperator\nfrom cosmos.providers.dbt.core.dag import DbtDag\n\nDBT_PROJECT_PATH = \"/path/para/seu/projeto/dbt\"\n\nwith DbtDag(\n     dag_id=\"dbt_cosmos_example\",\n     dbt_project_path=DBT_PROJECT_PATH,\n     profile_mapping=PostgresUserPasswordProfileMapping(\n          conn_id=\"airflow_db_conn_id\",\n          profile_args={\"schema\": \"public\"}\n     ),\n     schedule_interval=\"@daily\",\n     start_date=datetime(2023, 1, 1),\n     catchup=False,\n) as dag:\n     pass\n</code></pre> <ol> <li>Configure a conex\u00e3o no Airflow     No Airflow, crie uma conex\u00e3o (<code>conn_id</code>) compat\u00edvel com o banco de dados usado pelo dbt.</li> </ol>"},{"location":"documentacao/tutoriais/dbt/cosmos/#executando-os-modelos","title":"Executando os modelos","text":"<ul> <li>Ao iniciar a DAG, o Cosmos ir\u00e1 automaticamente criar tarefas para cada modelo do seu projeto dbt, permitindo monitoramento e reexecu\u00e7\u00e3o granular via Airflow.</li> </ul>"},{"location":"documentacao/tutoriais/dbt/cosmos/#evitando-conflito-de-logs","title":"Evitando conflito de logs","text":"<p>Cuidado: N\u00e3o remover as linhas abaixo do arquivo pois foram necess\u00e1rias para evitar erros com logs.</p> <pre><code># Jobs sendo executados em paralelo podem conflitar ao enviar os logs\n# para a mesma pasta, isso ir\u00e1 corrigir esse conflito\n\nfrom cosmos.constants import DBT_LOG_PATH_ENVVAR\n\ndbt_log_path = \"/tmp/dbt_logs\"\nos.makedirs(dbt_log_path, exist_ok=True)\nos.environ[DBT_LOG_PATH_ENVVAR] = dbt_log_path\n</code></pre>"},{"location":"documentacao/tutoriais/dbt/cosmos/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Documenta\u00e7\u00e3o oficial do Cosmos</li> <li>Integra\u00e7\u00e3o dbt + Airflow</li> </ul>"},{"location":"documentacao/tutoriais/dbt/dbt-docs/","title":"DBT Docs","text":"<p>DBT Docs \u00e9 uma funcionalidade do DBT que gera automaticamente documenta\u00e7\u00e3o para seus projetos de transforma\u00e7\u00e3o de dados.</p> <p>https://docs.getdbt.com/docs/build/documentation</p>"},{"location":"documentacao/tutoriais/dbt/dbt-docs/#exemplo-de-documentacao-yaml","title":"Exemplo de Documenta\u00e7\u00e3o YAML","text":"<p>Dentro da pasta <code>dags/dbt/ipea/models</code> est\u00e1 o arquivo <code>schema.yml</code> . O nome do arquivo pode ser alterado que ainda ser\u00e1 corretamente processado. Abaixo est\u00e1 um trecho do c\u00f3digo demonstrando como as informa\u00e7\u00f5es devem constar.</p> <pre><code>version: 2\n\nmodels:\n  - name: contratos\n    description: &gt;\n      Tabela com informa\u00e7\u00f5es sobre contratos, incluindo detalhes como o valor do contrato, a data de in\u00edcio e t\u00e9rmino, e o status do contrato.\n      Esta tabela \u00e9 fundamental para entender a execu\u00e7\u00e3o e o cumprimento dos contratos firmados.\n      A tabela \u00e9 atualizada diariamente e cont\u00e9m dados de contratos firmados pelo IPEA.\n    columns:\n      - name: id\n        description: &gt;\n          Identificador \u00fanico do contrato, utilizado para referenciar o contrato em outras tabelas e an\u00e1lises.\nmacros:\n    - name: create_udfs\n    description: &gt;\n      Fun\u00e7\u00e3o que cria as UDFs necess\u00e1rias para o funcionamento do projeto.\n      Essa fun\u00e7\u00e3o deve ser chamada no in\u00edcio de cada run para garantir que todas as UDFs estejam dispon\u00edveis.\n</code></pre>"},{"location":"documentacao/tutoriais/dbt/dbt-docs/#como-utilizar","title":"Como Utilizar","text":"<ol> <li> <p>Execute o comando para gerar a documenta\u00e7\u00e3o:</p> <pre><code>dbt docs generate\n</code></pre> <p>Verifique se <code>catalog.json</code>  e <code>manifest.json</code>  foram criados na pastas target</p> </li> <li> <p>Garanta que voc\u00ea criou os modelos com <code>dbt run</code> ou <code>dbt build</code> para visualizar a documenta\u00e7\u00e3o de todas as colunas, n\u00e3o apenas aquelas descritas no seu projeto.</p> </li> <li> <p>Inicie o servidor local de documenta\u00e7\u00e3o:</p> <pre><code>dbt docs serve\n</code></pre> </li> <li> <p>Acesse a documenta\u00e7\u00e3o no navegador (geralmente em http://localhost:8080)</p> </li> </ol>"},{"location":"documentacao/tutoriais/dbt/dbt-docs/#principais-recursos","title":"Principais Recursos","text":"<ul> <li>Visualiza\u00e7\u00e3o do DAG (Directed Acyclic Graph) dos modelos</li> <li>Documenta\u00e7\u00e3o autom\u00e1tica de modelos, colunas e testes</li> <li>Navega\u00e7\u00e3o interativa entre depend\u00eancias</li> <li>Visualiza\u00e7\u00e3o do c\u00f3digo SQL dos modelos</li> </ul>"},{"location":"documentacao/tutoriais/dbt/dbt-docs/#boas-praticas","title":"Boas Pr\u00e1ticas","text":"<ul> <li>Documente seus modelos usando blocos de documenta\u00e7\u00e3o em YAML</li> <li>Adicione descri\u00e7\u00f5es detalhadas para colunas importantes</li> <li>Mantenha a documenta\u00e7\u00e3o atualizada conforme o projeto evolui</li> <li>Use tags para organizar melhor seus modelos</li> </ul>"},{"location":"documentacao/tutoriais/dbt/macros/","title":"Macros","text":"<p>Macros no DBT (Data Build Tool) s\u00e3o blocos de c\u00f3digo reutiliz\u00e1veis escritos em SQL e Jinja que podem ser chamados em diferentes modelos do projeto. Eles funcionam como fun\u00e7\u00f5es que encapsulam l\u00f3gicas complexas ou repetitivas, tornando o c\u00f3digo mais limpo e manuten\u00edvel.</p> <p>https://docs.getdbt.com/docs/build/jinja-macros</p>"},{"location":"documentacao/tutoriais/dbt/macros/#principais-caracteristicas-das-macros","title":"Principais caracter\u00edsticas das Macros","text":"<ul> <li>Reutiliza\u00e7\u00e3o de c\u00f3digo: Permite escrever uma l\u00f3gica uma vez e reutiliz\u00e1-la em v\u00e1rios modelos</li> <li>Parametriza\u00e7\u00e3o: Aceita argumentos, tornando-as flex\u00edveis e adapt\u00e1veis a diferentes contextos</li> <li>Modularidade: Facilita a manuten\u00e7\u00e3o do c\u00f3digo ao centralizar l\u00f3gicas comuns em um \u00fanico lugar</li> </ul>"},{"location":"documentacao/tutoriais/dbt/macros/#tipos-comuns-de-macros","title":"Tipos comuns de Macros","text":"<p>Existem diferentes tipos de macros que podem ser utilizadas no DBT:</p> <ul> <li>Macros nativas: Fornecidas pelo pr\u00f3prio DBT, como current_timestamp() e generate_schema_name()</li> <li>Macros personalizadas: Criadas pelo usu\u00e1rio para atender necessidades espec\u00edficas do projeto</li> <li>Macros de pacotes: Disponibilizadas atrav\u00e9s de pacotes dbt, como dbt_utils</li> </ul>"},{"location":"documentacao/tutoriais/dbt/macros/#exemplo-de-macro","title":"Exemplo de Macro","text":"<pre><code>{% macro first_letter_uppercase_explicit(column) %}\n    UPPER(LEFT({{ column }}, 1)) || LOWER(SUBSTRING({{ column }}, 2))\n{% endmacro %}\n</code></pre> <p>Esta macro pode ser usada como no seguinte exemplo</p> <pre><code>SELECT \n    {{ first_letter_uppercase_explicit('first_name') }} as formatted_first_name,\n    {{ first_letter_uppercase_explicit('last_name') }} as formatted_last_name\nFROM users\n</code></pre> <p>Veja que a coluna \u00e9 passada como string, pois o compilador do DBT ir\u00e1 fazer a substitui\u00e7\u00e3o textual do modelo e no target aparecer\u00e1 como</p> <pre><code>SELECT \n    UPPER(LEFT(first_name, 1)) || LOWER(SUBSTRING(first_name, 2)) as formatted_first_name,\n    UPPER(LEFT(last_name, 1)) || LOWER(SUBSTRING(last_name, 2)) as formatted_last_name\nFROM users\n</code></pre>"},{"location":"documentacao/tutoriais/dbt/macros/#macros-presentes-no-projeto","title":"Macros presentes no projeto","text":"<p>As macros est\u00e3o armazenadas no diret\u00f3rio <code>macros/</code> dentro do projeto <code>dbt/ipea</code>. </p> <pre><code>macros/\n\u251c\u2500\u2500 udfs/\n\u2502   \u251c\u2500\u2500 f_format_nc.sql\n\u2502   \u2514\u2500\u2500 f_parse_dates.sql\n\u251c\u2500\u2500 create_udfs.sql\n\u251c\u2500\u2500 get_custom_schema.sql\n\u2514\u2500\u2500 parse_financial_value.sql\n</code></pre>"},{"location":"documentacao/tutoriais/dbt/macros/#user-defined-functions-udf","title":"User-Defined-Functions (UDF)","text":"<p>\u00c0 primeira vista UDFs e macros parecem ser substitu\u00edveis, por\u00e9m a primeira possui um potencial muito maior quanto \u00e0 complexidade. Caso a transforma\u00e7\u00e3o tenha muitas etapas \u00e9 recomendado usar UDF, mas sua utiliza\u00e7\u00e3o no DBT necessita algumas etapas extras. As UDFs ficam na pasta <code>/udfs</code> , tendo o formato <code>f_&lt;nome da fun\u00e7\u00e3o&gt;</code> . Aqui est\u00e1 um exemplo usado no projeto</p> <pre><code>{% macro create_f_format_nc() %}\n    create or replace function {{ target.schema }}.format_nc(in_text text)\n    returns text\n    as $$ \n\n    with \n\n    pre_process as (\n        select left(in_text, 7) as prefix,\n            right(in_text, 4)::numeric as posfix\n    )\n\n    select concat(prefix, to_char(posfix, 'FM00000')) as result\n    from pre_process \n\n    $$\n    language sql\n    ;\n{% endmacro %}\n</code></pre> <p>Somente isso n\u00e3o \u00e9 o suficiente para que os modelos possam utiliz\u00e1-la, para isso criamos a macro <code>create_udfs.sql</code> , que inicializa as fun\u00e7\u00f5es e as deixam prontas para uso</p> <pre><code>{% macro create_udfs() %}\n\ncreate schema if not exists {{ target.schema }};\n\n    {{ create_f_parse_dates() }}\n    ;\n    {{ create_f_format_nc() }}\n    ;\n\n{% endmacro %}\n</code></pre> <p>No arquivo <code>dbt_project.yml</code> foi adicionado a seguinte configura\u00e7\u00e3o:</p> <pre><code># outras configs\n\non-run-start:\n  - '{{create_udfs()}}'\n</code></pre> <p>Isso ir\u00e1 criar as fun\u00e7\u00f5es sempre quando um modelo for executado.</p>"},{"location":"documentacao/tutoriais/dbt/modelos/","title":"O que s\u00e3o modelos DBT?","text":"<p>Arquivos SQL para manipula\u00e7\u00e3o e cria\u00e7\u00e3o de tabelas referenci\u00e1veis e reutiliz\u00e1veis.</p>"},{"location":"documentacao/tutoriais/dbt/modelos/#configurando-dbt_projectyml","title":"Configurando dbt_project.yml","text":"<p>O arquivo <code>dbt_project.yml</code> \u00e9 o principal arquivo de configura\u00e7\u00e3o de um projeto DBT. Nele, voc\u00ea define informa\u00e7\u00f5es essenciais como o nome do projeto, diret\u00f3rios de modelos, configura\u00e7\u00f5es de materializa\u00e7\u00e3o padr\u00e3o, vari\u00e1veis, configura\u00e7\u00f5es de perfil de conex\u00e3o e outras op\u00e7\u00f5es que controlam o comportamento do DBT.</p> <p>Exemplo de <code>dbt_project.yml</code> usado no projeto com o IPEA:</p> <pre><code>name: 'ipea'\n\nversion: 1.0.0\nconfig-version: 2\n\nprofile: ipea\n\n# Definindo o caminho para algumas das funcionalidades\nmodel-paths: [\"models\"]\nanalysis-paths: [\"analyses\"]\ntest-paths: [\"tests\"]\nseed-paths: [\"seeds\"]\nmacro-paths: [\"macros\"]\nsnapshot-paths: [\"snapshots\"]\n\nclean-targets:\n  - \"target\"\n  - \"dbt_packages\"\n  - \"logs\"\n\n# Aqui define-se onde e como os modelos ser\u00e3o organizados, \n# assim como configura\u00e7\u00f5es padr\u00e3o de meterializa\u00e7\u00e3o\nmodels:\n  ipea: \n    +database: analytics\n    contratos_dbt:\n      +materialized: table\n      +schema: contratos\n      bronze:\n        +materialized: incremental\n      views:\n        +materialized: view\n    pessoas_dbt:\n      +materialized: table\n      +schema: pessoas\n      views:\n        +materialized: view\n    ted_dbt:\n      +materialized: table\n      +schema: ted\n      views:\n        +materialized: view\n\n# Essa configura\u00e7\u00e3o define a macro que ser\u00e1 executada \n# antes de cada modelos para criar as UDFs\non-run-start:\n  - '{{create_udfs()}}'\n</code></pre> <p>Esse arquivo garante que o DBT saiba onde encontrar os modelos, como execut\u00e1-los e quais padr\u00f5es aplicar durante o build do projeto.</p>"},{"location":"documentacao/tutoriais/dbt/modelos/#referenciando-um-modelo","title":"Referenciando um modelo","text":"<p>A depend\u00eancia entre modelos \u00e9 feita usando a sintaxe</p> <pre><code>select\n    ...\nfrom {{ ref('&lt;nome_do_modelo&gt;') }}\n</code></pre> <p>ap\u00f3s o <code>dbt build</code>, essa query \u00e9 compilada em</p> <pre><code>select\n    ...\nfrom schema.nome_do_modelo\n</code></pre> <p>caso o modelo seja realocado para outro esquema, no momento da compila\u00e7\u00e3o a refer\u00eancia se adapta \u00e0 mudan\u00e7a automaticamente</p>"},{"location":"documentacao/tutoriais/dbt/modelos/#sources","title":"Sources","text":"<p>Quando uma tabela possui origem que n\u00e3o seja atrav\u00e9s de um modelo dbt, usa-se <code>source</code> para referenci\u00e1-las</p> <pre><code>select \n    ...\nfrom {{ source('transfere_gov', 'contratos') }}\n</code></pre>"},{"location":"documentacao/tutoriais/dbt/modelos/#tipos-de-modelos","title":"Tipos de modelos","text":"<p>No DBT,  os modelos possuem diferentes tipos de materializa\u00e7\u00e3o, que servem prop\u00f3sitos espec\u00edficos:</p> <ul> <li>Table: Cria uma tabela f\u00edsica persistente que \u00e9 reconstru\u00edda a cada execu\u00e7\u00e3o</li> <li>View: Cria uma view SQL que \u00e9 reconstru\u00edda a cada consulta</li> <li>Incremental: Atualiza apenas os registros novos ou modificados, ideal para grandes conjuntos de dados</li> <li>Ephemeral: N\u00e3o cria objeto no banco, funciona como CTE (Common Table Expression) em outros modelos</li> </ul> <p>Cada tipo de materializa\u00e7\u00e3o tem seu caso de uso espec\u00edfico, dependendo das necessidades de performance, volume de dados e frequ\u00eancia de atualiza\u00e7\u00e3o.</p>"},{"location":"documentacao/tutoriais/dbt/modelos/#boas-praticas","title":"Boas pr\u00e1ticas","text":"<ul> <li>Utilizar nomenclatura clara e consistente</li> <li>Documentar todos os modelos e suas transforma\u00e7\u00f5es</li> <li>Implementar testes para validar a qualidade dos dados</li> <li>Manter o c\u00f3digo modular e reutiliz\u00e1vel</li> <li>Versionar os modelos usando controle de c\u00f3digo</li> </ul> <p>Com DBT, as equipes de dados podem construir transforma\u00e7\u00f5es confi\u00e1veis e escal\u00e1veis, facilitando a manuten\u00e7\u00e3o e evolu\u00e7\u00e3o do pipeline de dados anal\u00edticos.</p>"},{"location":"documentacao/tutoriais/dbt/snapshots/","title":"Snaphots","text":"<p>Snapshots s\u00e3o uma funcionalidade do DBT que permite rastrear e registrar mudan\u00e7as em dados ao longo do tempo, criando um hist\u00f3rico de altera\u00e7\u00f5es em tabelas espec\u00edficas.</p> <p>https://docs.getdbt.com/docs/build/snapshots</p>"},{"location":"documentacao/tutoriais/dbt/snapshots/#principais-caracteristicas","title":"Principais caracter\u00edsticas","text":"<ul> <li>Captura o estado dos dados em diferentes momentos</li> <li>Mant\u00e9m um registro hist\u00f3rico de altera\u00e7\u00f5es</li> <li>Permite an\u00e1lise de mudan\u00e7as ao longo do tempo</li> <li>\u00datil para auditoria e compliance</li> </ul>"},{"location":"documentacao/tutoriais/dbt/snapshots/#casos-de-uso-comuns","title":"Casos de uso comuns","text":"<ul> <li>Rastreamento de altera\u00e7\u00f5es em dados dimensionais</li> <li>Auditoria de mudan\u00e7as em dados sens\u00edveis</li> <li>An\u00e1lise hist\u00f3rica de altera\u00e7\u00f5es em tabelas</li> <li>Conformidade com requisitos regulat\u00f3rios</li> </ul>"},{"location":"documentacao/tutoriais/dbt/snapshots/#como-implementar","title":"Como implementar","text":"<p>Os snapshots funcionam atrav\u00e9s de duas estrat\u00e9gias principais:</p> <ol> <li>Timestamp Strategy<ul> <li>Utiliza colunas de timestamp para rastrear quando os registros foram atualizados pela \u00faltima vez.</li> <li>\u00c9 necess\u00e1rio de exista uma coluna que forne\u00e7a o momento da altera\u00e7\u00e3o (data ou timestamp) para que o dbt compare com o registro anterior e detecte que houve altera\u00e7\u00e3o</li> </ul> </li> <li>Check Strategy<ul> <li>Compara valores espec\u00edficos das colunas para identificar mudan\u00e7as nos registros. Se for detectada uma mudan\u00e7a em quaisquer dessas colunas, essa altera\u00e7\u00e3o ser\u00e1 registrada como uma nova linha da tabela de snapshots</li> </ul> </li> </ol>"},{"location":"documentacao/tutoriais/dbt/snapshots/#adicionando-snapshots-ao-projeto","title":"Adicionando snapshots ao projeto","text":"<p>Dentro da pasta <code>snapshots</code> , deve-se adicionar um arquivo <code>*.yml</code> descrevendo como o snapshot dever\u00e1 ser feito. Por exemplo temos <code>tables_snapshot.yml</code> , que configura todos os snapshots para o pipe de contratos. </p> <pre><code>snapshots:\n  - name: contratos_snapshot\n    relation: ref('contratos')\n    config:\n      schema: snapshots\n      database: analytics\n      unique_key: id\n      strategy: check\n      check_cols: [situacao, num_parcelas, valor_parcela, valor_global, valor_acumulado]\n</code></pre> <p>Isso define uma tabela <code>snapshots.contratos_snapshot</code>  que pode ser consultada para averiguar as altera\u00e7\u00f5es ao longo do tempo.</p>"},{"location":"documentacao/tutoriais/dbt/snapshots/#boas-praticas","title":"Boas pr\u00e1ticas","text":"<p>Para um uso efetivo dos snapshots, recomenda-se:</p> <ul> <li>Definir claramente quais tabelas precisam de snapshots</li> <li>Escolher a estrat\u00e9gia adequada para cada caso</li> <li>Manter uma pol\u00edtica de reten\u00e7\u00e3o de dados</li> <li>Documentar a configura\u00e7\u00e3o dos snapshots</li> </ul> <p>Os snapshots s\u00e3o uma ferramenta poderosa para manter a integridade e rastreabilidade dos dados em projetos DBT, especialmente em ambientes onde a an\u00e1lise hist\u00f3rica \u00e9 crucial.</p>"},{"location":"documentacao/tutoriais/dbt/testes/","title":"Testes","text":""},{"location":"documentacao/tutoriais/dbt/testes/#testes-singulares","title":"Testes Singulares","text":"<p>O DBT possui testes built-in que podem ser executados de forma singular, verificando aspectos espec\u00edficos dos dados:</p> <ul> <li>unique: Verifica se uma coluna ou combina\u00e7\u00e3o de colunas cont\u00e9m valores \u00fanicos</li> <li>not_null: Garante que uma coluna n\u00e3o contenha valores nulos</li> <li>accepted_values: Valida se os valores de uma coluna est\u00e3o dentro de um conjunto espec\u00edfico de valores permitidos</li> <li>relationships: Verifica integridade referencial entre tabelas</li> </ul>"},{"location":"documentacao/tutoriais/dbt/testes/#testes-genericos","title":"Testes Gen\u00e9ricos","text":"<p>Al\u00e9m disso, \u00e9 poss\u00edvel criar testes gen\u00e9ricos que podem ser reutilizados em diferentes modelos:</p> <ul> <li>Testes de schema para validar tipos de dados</li> <li>Verifica\u00e7\u00f5es de integridade de dados</li> <li>Valida\u00e7\u00f5es de regras de neg\u00f3cio</li> </ul> <p>Estes testes podem ser executados como parte do pipeline de dados, garantindo qualidade cont\u00ednua.</p> <p>A descri\u00e7\u00e3o dos testes gen\u00e9ricos podem ser encontrados na pasta <code>~/dbt/ipea/macros/data_quality</code> </p>"},{"location":"documentacao/tutoriais/dbt/testes/#configurando-testes-para-os-modelos","title":"Configurando testes para os modelos","text":"<p>Dentro da pasta <code>~/dbt/ipea/models</code> o arquivo <code>schema.yml</code> , que al\u00e9m de conter as descri\u00e7\u00f5es dos modelos tamb\u00e9m est\u00e3o configurados os testes de integridade. Aqui est\u00e1 um trecho do arquivo como exemplo</p> <pre><code># Este arquivo deve ser usado para descri\u00e7\u00f5es dos modelos\n# e para configurar testes\n\nversion: 2\n\nmodels:\n\n  # Contratos DBT\n\n  ## Bronze\n  - name: contratos # Nome do modelo\n    description: &gt;\n      Tabela com informa\u00e7\u00f5es sobre contratos, incluindo detalhes como o valor do contrato, a data de in\u00edcio e t\u00e9rmino, e o status do contrato.\n      Esta tabela \u00e9 fundamental para entender a execu\u00e7\u00e3o e o cumprimento dos contratos firmados.\n      A tabela \u00e9 atualizada diariamente e cont\u00e9m dados de contratos firmados pelo IPEA.\n    columns: # Descri\u00e7\u00e3o de cada coluna\n      - name: id\n        description: &gt;\n          Identificador \u00fanico do contrato, utilizado para referenciar o contrato em outras tabelas e an\u00e1lises.\n    data_tests: # Configura\u00e7\u00e3o dos testes\n      - row_count_match:\n          source_table: compras_gov.contratos\n          target_table: contratos.contratos\n [...]\n</code></pre> <p>Ap\u00f3s a compila\u00e7\u00e3o da DAG pelo Cosmos, pode-se conferir a seguinte estrutura no Airflow</p>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/","title":"CI/CD - Integra\u00e7\u00e3o e Entrega Cont\u00ednua","text":"<p>Este documento descreve a configura\u00e7\u00e3o de CI/CD (Continuous Integration/Continuous Deployment) para o projeto GovHub, incluindo a documenta\u00e7\u00e3o MkDocs e os containers Docker.</p>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>O projeto utiliza GitHub Actions para automatizar os processos de:</p> <ul> <li>Integra\u00e7\u00e3o Cont\u00ednua (CI): Valida\u00e7\u00e3o, testes e build autom\u00e1tico</li> <li>Entrega Cont\u00ednua (CD): Deploy autom\u00e1tico para diferentes ambientes</li> </ul>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#workflows-configurados","title":"Workflows Configurados","text":""},{"location":"documentacao/tutoriais/infraestrutura/cicd/#1-deploy-da-documentacao-deployyml","title":"1. Deploy da Documenta\u00e7\u00e3o (<code>deploy.yml</code>)","text":"<p>Automatiza o deploy da documenta\u00e7\u00e3o MkDocs para GitHub Pages.</p> <p>Triggers: - Push para branches <code>main</code> ou <code>master</code> - Pull requests - Execu\u00e7\u00e3o manual</p> <p>Funcionalidades: - Build da documenta\u00e7\u00e3o MkDocs - Deploy autom\u00e1tico para GitHub Pages - Valida\u00e7\u00e3o em Pull Requests - Cache de depend\u00eancias para melhor performance</p> <p>Configura\u00e7\u00e3o necess\u00e1ria: <pre><code># No reposit\u00f3rio GitHub, configure:\n# Settings &gt; Pages &gt; Source: GitHub Actions\n</code></pre></p> <p>Vari\u00e1veis de ambiente opcionais: - <code>GOOGLE_ANALYTICS_KEY</code>: Chave do Google Analytics</p>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#2-deploy-docker-docker-deployyml","title":"2. Deploy Docker (<code>docker-deploy.yml</code>)","text":"<p>Constr\u00f3i e publica imagens Docker do projeto.</p> <p>Triggers: - Push para branches principais - Tags de vers\u00e3o (<code>v*</code>) - Pull requests (apenas build, sem push)</p> <p>Funcionalidades: - Build multi-arquitetura (AMD64, ARM64) - Push para GitHub Container Registry - Versionamento autom\u00e1tico baseado em tags - Deploy para ambientes de staging e produ\u00e7\u00e3o</p> <p>Imagens geradas: <pre><code>ghcr.io/govhub-br/govhub:latest\nghcr.io/govhub-br/govhub:main\nghcr.io/govhub-br/govhub:v1.0.0\n</code></pre></p>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#3-validacao-da-documentacao-docs-validationyml","title":"3. Valida\u00e7\u00e3o da Documenta\u00e7\u00e3o (<code>docs-validation.yml</code>)","text":"<p>Valida a qualidade e integridade da documenta\u00e7\u00e3o.</p> <p>Triggers: - Push e Pull Requests - Execu\u00e7\u00e3o semanal autom\u00e1tica - Execu\u00e7\u00e3o manual</p> <p>Valida\u00e7\u00f5es realizadas: - Configura\u00e7\u00e3o do MkDocs - Links internos e externos - Arquivos \u00f3rf\u00e3os - Estrutura da documenta\u00e7\u00e3o - Estat\u00edsticas de conte\u00fado</p>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#configuracao-do-ambiente","title":"Configura\u00e7\u00e3o do Ambiente","text":""},{"location":"documentacao/tutoriais/infraestrutura/cicd/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<ol> <li> <p>GitHub Pages habilitado: <pre><code>Settings &gt; Pages &gt; Source: GitHub Actions\n</code></pre></p> </li> <li> <p>Secrets configurados (opcional): <pre><code>GOOGLE_ANALYTICS_KEY: Sua chave do Google Analytics\n</code></pre></p> </li> <li> <p>Permiss\u00f5es do reposit\u00f3rio: <pre><code>Settings &gt; Actions &gt; General &gt; Workflow permissions: Read and write\n</code></pre></p> </li> </ol>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#estrutura-de-branches","title":"Estrutura de Branches","text":"<ul> <li><code>main</code>/<code>master</code>: Branch principal, deploys autom\u00e1ticos</li> <li><code>develop</code>: Branch de desenvolvimento</li> <li>Feature branches: Valida\u00e7\u00e3o via PR</li> </ul>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#ambientes-de-deploy","title":"Ambientes de Deploy","text":""},{"location":"documentacao/tutoriais/infraestrutura/cicd/#documentacao-github-pages","title":"Documenta\u00e7\u00e3o (GitHub Pages)","text":"<ul> <li>URL: <code>https://govhub-br.github.io/govhub/</code></li> <li>Deploy: Autom\u00e1tico em push para main</li> <li>Tecnologia: MkDocs Material</li> </ul>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#container-registry","title":"Container Registry","text":"<ul> <li>Registry: GitHub Container Registry (ghcr.io)</li> <li>Imagens: Multi-arquitetura (AMD64, ARM64)</li> <li>Versionamento: Baseado em Git tags e branches</li> </ul>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#monitoramento-e-logs","title":"Monitoramento e Logs","text":""},{"location":"documentacao/tutoriais/infraestrutura/cicd/#visualizacao-de-workflows","title":"Visualiza\u00e7\u00e3o de Workflows","text":"<pre><code># Acesse: https://github.com/GovHub-br/govhub/actions\n</code></pre>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#status-badges","title":"Status Badges","text":"<p>Adicione ao README.md: <pre><code>![Deploy Status](https://github.com/GovHub-br/govhub/workflows/Deploy%20MkDocs%20to%20GitHub%20Pages/badge.svg)\n![Docker Build](https://github.com/GovHub-br/govhub/workflows/Build%20and%20Deploy%20Docker%20Container/badge.svg)\n</code></pre></p>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#desenvolvimento-local","title":"Desenvolvimento Local","text":""},{"location":"documentacao/tutoriais/infraestrutura/cicd/#testando-a-documentacao","title":"Testando a Documenta\u00e7\u00e3o","text":"<pre><code># Instalar depend\u00eancias\npip install -r requirements.txt\npip install mkdocs-material[recommended,imaging]\n\n# Servir localmente\nmkdocs serve\n\n# Build para produ\u00e7\u00e3o\nmkdocs build --strict\n</code></pre>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#testando-o-container","title":"Testando o Container","text":"<pre><code># Build local\ndocker build -t govhub-docs .\n\n# Executar localmente\ndocker run -p 8000:8000 govhub-docs\n\n# Usando docker-compose\ndocker-compose up govhub-docs\n</code></pre>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#troubleshooting","title":"Troubleshooting","text":""},{"location":"documentacao/tutoriais/infraestrutura/cicd/#problemas-comuns","title":"Problemas Comuns","text":"<ol> <li>Build falha no GitHub Actions:</li> <li>Verifique se todas as depend\u00eancias est\u00e3o no <code>requirements.txt</code></li> <li> <p>Confirme que o <code>mkdocs.yml</code> est\u00e1 v\u00e1lido</p> </li> <li> <p>Deploy n\u00e3o funciona:</p> </li> <li>Verifique se GitHub Pages est\u00e1 habilitado</li> <li> <p>Confirme as permiss\u00f5es do workflow</p> </li> <li> <p>Links quebrados:</p> </li> <li>Execute <code>mkdocs build --strict</code> localmente</li> <li>Use o workflow de valida\u00e7\u00e3o para identificar problemas</li> </ol>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#logs-e-debug","title":"Logs e Debug","text":"<pre><code># Ver logs detalhados do MkDocs\nmkdocs build --verbose\n\n# Validar configura\u00e7\u00e3o\nmkdocs config\n\n# Testar plugins\nmkdocs serve --verbose\n</code></pre>"},{"location":"documentacao/tutoriais/infraestrutura/cicd/#migracao-do-gitlab","title":"Migra\u00e7\u00e3o do GitLab","text":"<p>Para a maioria das aplica\u00e7\u00f5es estamos usando imagens de containers p\u00fablicos, por\u00e9m para o caso do Airflow \u00e9 necess\u00e1rio instalar algumas depend\u00eancias para garantir que temos todas as bibliotecas necess\u00e1rias para rodar das DAGs, para esse caso foi implementado um passo extra no CI do gitlab garantido que qualquer mudan\u00e7a no <code>Dockerfile</code> ou no <code>requirements.txt</code> gere uma vers\u00e3o nova da imagem do Airflow e publique a mesma no reposit\u00f3rio p\u00fablico do gitlab.</p> <p>O processo de atualiza\u00e7\u00e3o da imagem do Airflow ficou manual para garantir que o usu\u00e1rio que atualizou as depend\u00eancias se responsabilize por subir a imagem nova e verificar que nada quebrou no processo de atualiza\u00e7\u00e3o.</p> <p>Nota: Com a migra\u00e7\u00e3o para GitHub Actions, este processo foi automatizado e melhorado com valida\u00e7\u00f5es adicionais.</p>"},{"location":"documentacao/tutoriais/infraestrutura/postgresql/","title":"PostgreSQL","text":"<p>PostgreSQL \u00e9 um sistema de gerenciamento de banco de dados objeto-relacional. Ele oferece os benef\u00edcios de um banco de dados relacional, ****enquanto fornece suporte para objetos definidos pelo usu\u00e1rio e heran\u00e7a de tabelas. Essa combina\u00e7\u00e3o de recursos faz do PostgreSQL uma escolha vers\u00e1til para aplica\u00e7\u00f5es que precisam lidar com diversos tipos de dados e relacionamentos complexos.</p>"},{"location":"documentacao/tutoriais/infraestrutura/postgresql/#banco-de-dados-relacional","title":"Banco de dados relacional","text":"<p>Os bancos de dados relacionais oferecem v\u00e1rias vantagens importantes:</p> <ul> <li>Integridade dos dados: Garantem consist\u00eancia atrav\u00e9s de restri\u00e7\u00f5es, chaves estrangeiras e regras de valida\u00e7\u00e3o.</li> <li>Estrutura organizada: Dados s\u00e3o armazenados em tabelas com rela\u00e7\u00f5es claramente definidas, facilitando a compreens\u00e3o e manuten\u00e7\u00e3o.</li> <li>Consultas complexas: Suportam SQL para realizar consultas sofisticadas, jun\u00e7\u00f5es entre tabelas e agrega\u00e7\u00f5es de dados.</li> <li>Transa\u00e7\u00f5es ACID: Garantem Atomicidade, Consist\u00eancia, Isolamento e Durabilidade nas opera\u00e7\u00f5es.</li> <li>Normaliza\u00e7\u00e3o: Reduz redund\u00e2ncia de dados e melhora a efici\u00eancia do armazenamento.</li> <li>Controle de acesso: Oferecem sistemas robustos de permiss\u00f5es e seguran\u00e7a para proteger os dados.</li> <li>Escalabilidade: Podem crescer para lidar com grandes volumes de dados mantendo o desempenho.</li> </ul> <p>Essas caracter\u00edsticas tornam os bancos de dados relacionais ideais para aplica\u00e7\u00f5es que necessitam de confiabilidade, consist\u00eancia e capacidade de realizar opera\u00e7\u00f5es complexas com os dados.</p>"},{"location":"documentacao/tutoriais/infraestrutura/postgresql/#objetos-definidos-pelo-usuario","title":"Objetos definidos pelo usu\u00e1rio","text":"<p>Os objetos definidos pelo usu\u00e1rio no PostgreSQL permitem estender a funcionalidade do banco de dados al\u00e9m dos tipos de dados padr\u00e3o. Alguns exemplos incluem:</p> <ul> <li>Tipos de dados personalizados: Permitem criar novos tipos de dados espec\u00edficos para a aplica\u00e7\u00e3o, como coordenadas geogr\u00e1ficas ou estruturas complexas.</li> <li>Fun\u00e7\u00f5es customizadas: Possibilitam encapsular l\u00f3gica de neg\u00f3cio complexa diretamente no banco de dados, podendo ser escritas em v\u00e1rias linguagens como SQL, PL/pgSQL, Python ou C.</li> <li>Operadores personalizados: Permitem definir novas opera\u00e7\u00f5es para tipos de dados existentes ou personalizados.</li> <li>Dom\u00ednios: S\u00e3o tipos de dados personalizados baseados em tipos existentes, mas com restri\u00e7\u00f5es adicionais.</li> </ul> <p>Esses objetos definidos pelo usu\u00e1rio tornam o PostgreSQL extremamente flex\u00edvel, permitindo que desenvolvedores adaptem o banco de dados \u00e0s necessidades espec\u00edficas de suas aplica\u00e7\u00f5es.</p>"},{"location":"documentacao/tutoriais/infraestrutura/postgresql/#heranca-de-tabela","title":"Heran\u00e7a de tabela","text":"<p>A heran\u00e7a de tabela no PostgreSQL \u00e9 um recurso que permite uma tabela herdar as colunas de outra tabela. Este conceito \u00e9 similar \u00e0 heran\u00e7a em programa\u00e7\u00e3o orientada a objetos. Principais aspectos da heran\u00e7a de tabela:</p> <ul> <li>Reutiliza\u00e7\u00e3o de estrutura: Uma tabela filha herda automaticamente todas as colunas da tabela pai, evitando duplica\u00e7\u00e3o de defini\u00e7\u00f5es.</li> <li>Extensibilidade: A tabela filha pode adicionar suas pr\u00f3prias colunas al\u00e9m das herdadas, permitindo especializa\u00e7\u00e3o.</li> <li>Consultas flex\u00edveis: Consultas na tabela pai podem incluir automaticamente dados das tabelas filhas, facilitando buscas abrangentes.</li> <li>Restri\u00e7\u00f5es: Constraints da tabela pai s\u00e3o herdadas pelas tabelas filhas, mantendo a integridade dos dados.</li> </ul> <p>A heran\u00e7a de tabela \u00e9 particularmente \u00fatil em cen\u00e1rios como:</p> <ul> <li>Particionamento de dados: Dividir grandes conjuntos de dados em tabelas menores mais gerenci\u00e1veis.</li> <li>Modelagem de hierarquias: Representar relacionamentos hier\u00e1rquicos naturais entre entidades.</li> <li>Especializa\u00e7\u00e3o de dados: Criar vers\u00f5es especializadas de uma estrutura de dados base.</li> </ul>"},{"location":"documentacao/tutoriais/infraestrutura/postgresql/#dicas-de-manipulacao","title":"Dicas de manipula\u00e7\u00e3o","text":""},{"location":"documentacao/tutoriais/infraestrutura/postgresql/#joins","title":"Joins","text":"<p>Ao realizar um join devemos sempre explicitar uma regra de associa\u00e7\u00e3o. S\u00e3o duas as maneiras que isso pode ser feito:</p>"},{"location":"documentacao/tutoriais/infraestrutura/postgresql/#on","title":"ON","text":"<p>Usando o operado <code>ON</code> , que realiza linha a linha uma opera\u00e7\u00e3o l\u00f3gica, que compara as as colunas da esquerda com a da direita, se retornar positivo a linha contendo dados de ambos os lados \u00e9 criada. Se uma linha da esqueda tiver v\u00e1rios correspondentes \u00e0 direita, ent\u00e3o m\u00faltiplas linhas s\u00e3o criadas</p> <pre><code>SELECT a.column_a, b.column_b, a.data_a, b.data_b\nFROM a_table a\nLEFT JOIN b_table b\nON( a.column_a = b.column_b)\n</code></pre>"},{"location":"documentacao/tutoriais/infraestrutura/postgresql/#using","title":"USING","text":"<p>O operador <code>USING</code>  simplifica o caso anterior quando a opera\u00e7\u00e3o l\u00f3gica \u00e9 uma compara\u00e7\u00e3o de igualdade. Neste caso \u00e9 necess\u00e1rio que as colunas tenham o mesmo nome.</p> <pre><code>SELECT column_id, a.data_a, b.data_b\nFROM a_table a\nLEFT JOIN b_table b\nUSING(column_id)\n</code></pre> <p>Aqui, quando usamos <code>SELECT *</code> , as colunas usadas no join n\u00e3o ser\u00e3o duplicadas. O mesmo n\u00e3o acontece ao usa <code>ON</code> .</p>  \u26a0\ufe0f AVISO IMPORTANTE: Ao realizar joins, sempre verifique cuidadosamente o tipo de join (INNER, LEFT, RIGHT, FULL) e as condi\u00e7\u00f5es de jun\u00e7\u00e3o. Joins incorretos podem resultar em: - Perda n\u00e3o intencional de dados - Duplica\u00e7\u00e3o de registros - Resultados inconsistentes - Problemas de performance em grandes conjuntos de dados"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/","title":"Gov Hub BR \u2014 Integra\u00e7\u00e3o com sistemas estruturantes","text":"<p>O Gov Hub BR \u00e9 uma plataforma livre e colaborativa voltada \u00e0 integra\u00e7\u00e3o de dados e informa\u00e7\u00f5es governamentais. A proposta central do projeto \u00e9 enfrentar um dos maiores desafios da gest\u00e3o p\u00fablica: a fragmenta\u00e7\u00e3o e a inconsist\u00eancia dos dados entre os diversos sistemas governamentais.</p> <p>O objetivo desta p\u00e1gina \u00e9 apresentar as principais fontes que estamos utilizando ao consultar dados p\u00fablicos e apresentar um direcionamento de onde essas documenta\u00e7\u00f5es especif\u00edcas podem ser usadas, de forma geral, sempre que quisermos importar um banco de dados de algum sistema utilizaremos suas APIS abertas para fazer a solicita\u00e7\u00e3o desses dados</p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#como-importar-um-banco-de-dados-de-sistema-estruturante","title":"Como importar um banco de dados de sistema estruturante","text":"<p>Este guia apresenta o processo para importar dados de sistemas governamentais estruturantes, como o SIAFI, Compras Gov e TransfereGov, utilizando suas APIs p\u00fablicas e respeitando boas pr\u00e1ticas de seguran\u00e7a e integra\u00e7\u00e3o.</p> <p>Foi feita uma refatora\u00e7\u00e3o dos clientes de API do antigo reposit\u00f3rio para o novo e implementados a base dos clients REST e SOAP. A partir disso os demais clientes de ingest\u00e3o foram desenvolvidos pela equipe do Lappis a partir do cliente base e dos exemplos. A biblioteca httpx (https://www.python-httpx.org/) foi escolhida por ser uma vers\u00e3o de cliente REST mais moderna e de f\u00e1cil interc\u00e2mbio para uma poss\u00edvel vers\u00e3o ass\u00edncrona caso o projeto necessite no futuro. Buscou-se fazer uso extensivo de logging, exemplo que foi seguido na implementa\u00e7\u00e3o das DAGs do Airflow de Ingest\u00e3o pela equipe do Lappis. </p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#integracao-com-o-siafi-sistema-integrado-de-administracao-financeira","title":"Integra\u00e7\u00e3o com o SIAFI (Sistema Integrado de Administra\u00e7\u00e3o Financeira)","text":""},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#apis-publicas-disponiveis","title":"APIs p\u00fablicas dispon\u00edveis","text":"<ul> <li>Consultar tabelas administrativas \u2014 Cat\u00e1logo de APIs governamentais</li> <li>Manter contas a pagar e receber \u2014 Cat\u00e1logo de APIs governamentais</li> <li>Manter programa\u00e7\u00e3o \u2014 Cat\u00e1logo de APIs governamentais</li> <li>M\u00f3dulo or\u00e7ament\u00e1rio \u2014 Cat\u00e1logo de APIs governamentais</li> </ul>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#integracao-siafi","title":"Integra\u00e7\u00e3o siafi","text":"<p>Antes de consumir as APIs do SIAFI, \u00e9 necess\u00e1rio realizar a configura\u00e7\u00e3o de um ambiente seguro.</p> <p>Mais informa\u00e7\u00f5es detalhadas est\u00e3o dispon\u00edveis no portal oficial: Informa\u00e7\u00f5es sobre a integra\u00e7\u00e3o com o SIAFI \u2014 Tesouro Nacional</p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#integracao-com-compras-gov","title":"Integra\u00e7\u00e3o com Compras Gov","text":"<p>O Gov Hub BR atualmente consome dados da seguinte API p\u00fablica: API de Compras Governamentais \u2014 compras.dados.gov.br</p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#integracao-com-o-transferegov","title":"Integra\u00e7\u00e3o com o TransfereGov","text":"<p>Para integra\u00e7\u00e3o com programas e transfer\u00eancias volunt\u00e1rias, acesse a documenta\u00e7\u00e3o oficial: APIs do TransfereGov \u2014 gov.br</p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#catalogo-de-apis-governamentais","title":"Cat\u00e1logo de APIs governamentais","text":"<p>A busca por novas fontes de dados pode ser feita no cat\u00e1logo oficial do governo federal: Cat\u00e1logo de APIs governamentais \u2014 ConectaGov</p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/importar_bancos/#conclusao","title":"Conclus\u00e3o","text":"<p>A proposta do Gov Hub BR \u00e9 democratizar o acesso a dados p\u00fablicos de forma segura, reutiliz\u00e1vel e tecnicamente s\u00f3lida. A partir da integra\u00e7\u00e3o com APIs governamentais documentadas e abertas, \u00e9 poss\u00edvel construir bases de dados qualificadas que fortalecem a gest\u00e3o p\u00fablica e aumentam a transpar\u00eancia.</p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/sistemas-estruturantes/","title":"Integra\u00e7\u00e3o de Dados dos Sistemas Estruturantes","text":"<p>Este documento detalha como implementar a extra\u00e7\u00e3o de dados e</p>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/sistemas-estruturantes/#1-extracao-de-dados-usando-api","title":"1. Extra\u00e7\u00e3o de Dados usando API","text":""},{"location":"documentacao/tutoriais/sistemas-estruturantes/sistemas-estruturantes/#11-configuracao-de-conexoes-e-variaveis","title":"1.1. Configura\u00e7\u00e3o de Conex\u00f5es e Vari\u00e1veis","text":"<ul> <li> <p>Defina conex\u00f5es no Airflow (<code>Admin &gt; Connections</code>) para cada API, se aplic\u00e1vel.</p> </li> <li> <p>Use <code>Variables</code> para par\u00e2metros gen\u00e9ricos:</p> </li> <li><code>api_timeout</code> (em segundos)</li> <li><code>retry_attempts</code></li> </ul>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/sistemas-estruturantes/#12-estrutura-das-dags","title":"1.2. Estrutura das DAGs","text":"<p>Exemplo de DAG para extra\u00e7\u00e3o de um \u00f3rg\u00e3o:</p> <pre><code>import logging\nimport yaml\nfrom airflow.decorators import dag, task\nfrom airflow.operators.trigger_dagrun import TriggerDagRunOperator\nfrom airflow.models import Variable\nfrom datetime import datetime, timedelta\nfrom postgres_helpers import get_postgres_conn\nfrom cliente_contratos import ClienteContratos\nfrom cliente_postgres import ClientPostgresDB\n\n\n@dag(\n    schedule_interval=\"@daily\",\n    start_date=datetime(2023, 1, 1),\n    catchup=False,\n    default_args={\n        \"owner\": \"Davi\",\n        \"retries\": 1,\n        \"retry_delay\": timedelta(minutes=5),\n    },\n    tags=[\"contratos_api\"],\n)\ndef api_contratos_dag() -&gt; None:\n    \"\"\"DAG para buscar e armazenar contratos por \u00f3rg\u00e3o definido.\"\"\"\n\n    @task\n    def fetch_and_store_contratos() -&gt; None:\n        logging.info(\"[contratos_ingest_dag.py] Iniciando extra\u00e7\u00e3o\")\n\n        orgao_alvo = Variable.get(\"airflow_orgao\", default_var=None)\n        if not orgao_alvo:\n            logging.error(\"Vari\u00e1vel airflow_orgao n\u00e3o definida!\")\n            raise ValueError(\"airflow_orgao n\u00e3o definida\")\n\n        orgaos_config_str = Variable.get(\"airflow_variables\", default_var=\"{}\")\n        orgaos_config = yaml.safe_load(orgaos_config_str)\n\n        codigos_ug = orgaos_config.get(orgao_alvo, {}).get(\"codigos_ug\", [])\n\n        if not codigos_ug:\n            logging.warning(f\"Nenhum c\u00f3digo UG encontrado para o \u00f3rg\u00e3o '{orgao_alvo}'\")\n            return\n\n        api = ClienteContratos()\n        postgres_conn_str = get_postgres_conn()\n        db = ClientPostgresDB(postgres_conn_str)\n\n        for ug_code in codigos_ug:\n            logging.info(f\"Buscando contratos para UG: {ug_code}\")\n            contratos = api.get_contratos_by_ug(ug_code)\n\n            if contratos:\n                logging.info(f\"Inserindo contratos da UG {ug_code} no schema compras_gov\")\n                db.insert_data(\n                    contratos,\n                    \"contratos\",\n                    conflict_fields=[\"id\"],\n                    primary_key=[\"id\"],\n                    schema=\"compras_gov\",\n                )\n            else:\n                logging.warning(f\"Nenhum contrato encontrado para UG {ug_code}\")\n\n    trigger_contratos_inativos = TriggerDagRunOperator(\n        task_id=\"trigger_contratos_inativos\",\n        trigger_dag_id=\"api_contratos_inativos_dag\",\n        wait_for_completion=False,\n    )\n\n    fetch_and_store_contratos() &gt;&gt; trigger_contratos_inativos\n\n\ndag_instance = api_contratos_dag()\n</code></pre>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/sistemas-estruturantes/#13-boas-praticas","title":"1.3. Boas Pr\u00e1ticas","text":"<ul> <li>Evite DAGs monol\u00edticas: crie fun\u00e7\u00f5es e subDAGs para cada recurso.</li> <li>Implemente alertas para falhas cr\u00edticas.</li> <li>Documente endpoints e vers\u00f5es de API.</li> </ul>"},{"location":"documentacao/tutoriais/sistemas-estruturantes/sistemas-estruturantes/#2-extracao-de-sados-usando-e-mail","title":"2. Extra\u00e7\u00e3o de Sados usando e-mail","text":""},{"location":"documentacao/tutoriais/superset/conexoes/","title":"Conex\u00f5es","text":""},{"location":"documentacao/tutoriais/superset/conexoes/#conectando-o-superset-ao-banco-de-dados-postgresql","title":"Conectando o Superset ao banco de dados PostgreSQL","text":"<ol> <li>Acesse o Superset no navegador.</li> <li>No canto superior direito, clique no bot\u00e3o <code>+</code> e selecione <code>Data</code> \u2192 <code>Connect Database</code>.</li> <li>Escolha o tipo de banco de dados (PostgreSQL).</li> <li>Preencha os dados de conex\u00e3o. Voc\u00ea pode usar a URI SQLAlchemy:</li> </ol> <pre><code>postgresql://usuario:senha@host:porta/nome_do_banco\n</code></pre> <p>\ud83d\udca1 Dica: Se estiver usando Docker, o host pode ser <code>host.docker.internal</code>.</p> <ol> <li>Clique em <code>Test Connection</code> para verificar a conex\u00e3o.</li> <li>Se tudo estiver correto, clique em <code>Connect</code> para salvar.</li> </ol>"},{"location":"documentacao/tutoriais/superset/conexoes/#gerenciando-acesso-a-dashboards","title":"Gerenciando acesso a dashboards","text":"<ul> <li>Propriet\u00e1rios: t\u00eam permiss\u00e3o para editar.</li> <li>Usu\u00e1rios n\u00e3o-propriet\u00e1rios: acesso pode ser gerenciado de duas formas:</li> <li>Permiss\u00f5es por dataset: se o usu\u00e1rio tiver acesso ao dataset, tamb\u00e9m pode ver os dashboards que o usam.</li> <li>Dashboard Roles (RBAC): se ativado, voc\u00ea pode definir quem v\u00ea o dashboard, independentemente do dataset.</li> </ul>"},{"location":"documentacao/tutoriais/superset/criando-chart/","title":"Criando uma visualiza\u00e7\u00e3o","text":""},{"location":"documentacao/tutoriais/superset/criando-chart/#registrando-um-dataset-tabela","title":"Registrando um Dataset (Tabela)","text":"<ol> <li>V\u00e1 at\u00e9 <code>Data</code> \u2192 <code>Datasets</code>.  </li> <li>Clique no bot\u00e3o <code>+ Dataset</code> no canto superior direito.  </li> <li> <p>Na janela que abrir:</p> <ul> <li>Escolha o banco de dados conectado.</li> <li>Selecione o Schema.</li> <li>Escolha a Tabela que deseja analisar.</li> </ul> </li> <li> <p>Clique em <code>Add</code> para registrar o dataset.</p> </li> </ol>"},{"location":"documentacao/tutoriais/superset/criando-chart/#personalizando-as-colunas-opcional","title":"Personalizando as colunas (opcional)","text":"<ol> <li>Ap\u00f3s adicionar um dataset, clique nele na lista.</li> <li>Clique em <code>Edit Dataset</code> (\u00edcone de l\u00e1pis).</li> <li> <p>Para cada coluna, voc\u00ea pode:</p> <ul> <li>Marcar se \u00e9 temporal (datas/hor\u00e1rios).</li> <li>Definir como filtr\u00e1vel.</li> <li>Adicionar descri\u00e7\u00f5es ou express\u00f5es personalizadas.</li> <li>Criar m\u00e9tricas virtuais (ex: <code>SUM(receita</code>).</li> <li>Criar colunas calculadas (ex: <code>CAST(valor AS FLOAT)</code>).</li> </ul> </li> </ol>"},{"location":"documentacao/tutoriais/superset/criando-chart/#criando-graficos-charts","title":"Criando gr\u00e1ficos (charts)","text":"<ol> <li>No menu Datasets, clique no nome do dataset que deseja visualizar.  </li> <li>Isso abrir\u00e1 o modo Explore, onde voc\u00ea pode criar gr\u00e1ficos com interface no-code.  </li> <li> <p>Na tela de Explore:</p> <ul> <li>Selecione o tipo de visualiza\u00e7\u00e3o (ex: Bar Chart, Time Series, Pie, etc).</li> <li>Defina a m\u00e9trica (ex: soma de vendas).</li> <li>Escolha dimens\u00f5es e filtros (ex: por regi\u00e3o, por produto).</li> </ul> </li> <li> <p>Clique em <code>Run</code> para visualizar o gr\u00e1fico.  </p> </li> <li> <p>Quando estiver satisfeito, clique em <code>Save</code>:</p> <ul> <li>D\u00ea um nome ao gr\u00e1fico.</li> <li>Escolha adicionar a um dashboard existente ou criar um novo.</li> </ul> </li> </ol>"},{"location":"documentacao/tutoriais/superset/criando-dashboard/","title":"Criando um dashboard","text":""},{"location":"documentacao/tutoriais/superset/criando-dashboard/#adicionando-charts","title":"Adicionando charts","text":"<ol> <li>Ap\u00f3s salvar o gr\u00e1fico, selecione <code>Save and go to Dashboard</code>.  </li> <li>No dashboard, clique em <code>Edit Dashboard</code> (canto superior direito).  </li> <li> <p>Agora \u00e9 poss\u00edvel:</p> <ul> <li>Redimensionar os gr\u00e1ficos (arrastar as bordas).</li> <li>Mover os gr\u00e1ficos pela grade.</li> <li>Adicionar outros charts, markdowns e filtros.</li> </ul> </li> <li> <p>Clique em <code>Save</code> para salvar o layout do dashboard.</p> </li> </ol>"},{"location":"documentacao/tutoriais/superset/criando-dashboard/#filtros","title":"Filtros","text":""},{"location":"documentacao/tutoriais/superset/criando-dashboard/#customizando-a-visualizacao-do-dashboard-via-url","title":"Customizando a visualiza\u00e7\u00e3o do dashboard via URL","text":"<p>Voc\u00ea pode adicionar par\u00e2metros \u00e0 URL para alterar como o dashboard \u00e9 exibido:</p> Par\u00e2metro Op\u00e7\u00f5es Descri\u00e7\u00e3o <code>standalone</code> 0 (default), 1, 2, 3 Remove elementos da interface (ex: navega\u00e7\u00e3o, t\u00edtulo) <code>show_filters</code> 0, 1 (default) Oculta ou exibe a barra de filtros <code>expand_filters</code> 0, 1 Controla se a barra de filtros aparece expandida <p>Exemplo de URL: <pre><code>http://localhost:8088/superset/dashboard/my-dashboard/?standalone=1&amp;show_filters=0\n</code></pre></p>"},{"location":"sobre-projeto/equipe/","title":"Equipe","text":""},{"location":"sobre-projeto/equipe/#unb","title":"UnB","text":""},{"location":"sobre-projeto/equipe/#ipea","title":"Ipea","text":""},{"location":"sobre-projeto/equipe/#capibari","title":"Capibari","text":""},{"location":"sobre-projeto/gestao-dados/","title":"Gest\u00e3o Orientada a Dados: Transformando Decis\u00f5es no Setor P\u00fablico","text":"<p>A gest\u00e3o orientada a dados \u00e9 uma abordagem estrat\u00e9gica que reconhece os dados como um dos ativos mais valiosos para a tomada de decis\u00e3o. No contexto do setor p\u00fablico, essa pr\u00e1tica tem o potencial de revolucionar a formula\u00e7\u00e3o e implementa\u00e7\u00e3o de pol\u00edticas p\u00fablicas, garantindo efici\u00eancia, transpar\u00eancia e responsabilidade.</p>"},{"location":"sobre-projeto/gestao-dados/#por-que-a-gestao-orientada-a-dados-e-essencial","title":"Por que a Gest\u00e3o Orientada a Dados \u00e9 Essencial?","text":"<ol> <li> <p>Decis\u00f5es Baseadas em Evid\u00eancias    Com dados confi\u00e1veis e bem estruturados, gestores podem fundamentar suas escolhas em an\u00e1lises concretas, reduzindo a depend\u00eancia de intui\u00e7\u00f5es ou suposi\u00e7\u00f5es.</p> </li> <li> <p>Integra\u00e7\u00e3o e Interoperabilidade    A abordagem integra informa\u00e7\u00f5es provenientes de diferentes sistemas estruturantes, eliminando redund\u00e2ncias e promovendo uma vis\u00e3o unificada.</p> </li> <li> <p>Aumento da Transpar\u00eancia    O uso de dados facilita o acesso a informa\u00e7\u00f5es estrat\u00e9gicas, permitindo maior presta\u00e7\u00e3o de contas e confian\u00e7a p\u00fablica.</p> </li> <li> <p>Monitoramento de Resultados    Indicadores e m\u00e9tricas de desempenho ajudam a monitorar metas, avaliar impactos e ajustar estrat\u00e9gias de forma \u00e1gil.</p> </li> </ol>"},{"location":"sobre-projeto/gestao-dados/#elementos-centrais-da-gestao-orientada-a-dados","title":"Elementos Centrais da Gest\u00e3o Orientada a Dados","text":""},{"location":"sobre-projeto/gestao-dados/#1-qualificacao-e-governanca-de-dados","title":"1. Qualifica\u00e7\u00e3o e Governan\u00e7a de Dados","text":"<p>A qualifica\u00e7\u00e3o dos dados \u00e9 a base para gerar informa\u00e7\u00f5es \u00fateis e acion\u00e1veis. Isso envolve:</p> <ul> <li>Identifica\u00e7\u00e3o de fontes confi\u00e1veis.</li> <li>Valida\u00e7\u00e3o de dados para evitar inconsist\u00eancias.</li> <li>Modelagem dos dados em tabelas organizadas para an\u00e1lises mais detalhadas.</li> </ul>"},{"location":"sobre-projeto/gestao-dados/#2-automacao-e-eficiencia-operacional","title":"2. Automa\u00e7\u00e3o e Efici\u00eancia Operacional","text":"<p>Ferramentas como Airflow s\u00e3o utilizadas para automatizar a coleta e o processamento de dados, permitindo:</p> <ul> <li>Pipelines eficientes para grandes volumes de informa\u00e7\u00f5es.</li> <li>Redu\u00e7\u00e3o de erros operacionais atrav\u00e9s de processos automatizados.</li> </ul>"},{"location":"sobre-projeto/gestao-dados/#3-modelagem-dimensional-e-integracao","title":"3. Modelagem Dimensional e Integra\u00e7\u00e3o","text":"<p>Por meio do DBT (Data Build Tool), os dados s\u00e3o transformados em modelos dimensionais que:</p> <ul> <li>Facilitam an\u00e1lises espec\u00edficas.</li> <li>Garantem que tabelas estejam organizadas para integra\u00e7\u00f5es futuras entre diferentes sistemas estruturantes.</li> </ul>"},{"location":"sobre-projeto/gestao-dados/#beneficios-para-o-setor-publico","title":"Benef\u00edcios para o Setor P\u00fablico","text":""},{"location":"sobre-projeto/gestao-dados/#eficiencia-administrativa","title":"Efici\u00eancia Administrativa","text":"<p>A elimina\u00e7\u00e3o de tarefas redundantes e a automa\u00e7\u00e3o de processos cr\u00edticos reduzem custos e otimizam os recursos p\u00fablicos.</p>"},{"location":"sobre-projeto/gestao-dados/#tomada-de-decisao-baseada-em-dados","title":"Tomada de Decis\u00e3o Baseada em Dados","text":"<p>Com dashboards interativos e relat\u00f3rios detalhados, gestores t\u00eam acesso a informa\u00e7\u00f5es em tempo real para tomar decis\u00f5es estrat\u00e9gicas.</p>"},{"location":"sobre-projeto/gestao-dados/#responsabilidade-e-confianca","title":"Responsabilidade e Confian\u00e7a","text":"<p>Dados bem organizados e acess\u00edveis fortalecem a confian\u00e7a da sociedade na gest\u00e3o p\u00fablica, aumentando a transpar\u00eancia e permitindo maior controle social.</p>"},{"location":"sobre-projeto/gestao-dados/#caminhos-para-o-futuro","title":"Caminhos para o Futuro","text":"<p>O futuro da gest\u00e3o orientada a dados est\u00e1 alinhado \u00e0 ado\u00e7\u00e3o de padr\u00f5es abertos, intelig\u00eancia artificial e big data. Isso permitir\u00e1:</p> <ul> <li>Antecipa\u00e7\u00e3o de tend\u00eancias com base em an\u00e1lises preditivas.</li> <li>Tomada de decis\u00e3o mais proativa e eficaz.</li> <li>Constru\u00e7\u00e3o de um ecossistema integrado, onde os dados s\u00e3o tratados como ativos estrat\u00e9gicos e compartilhados de forma \u00e9tica e segura.</li> </ul> <p>A gest\u00e3o orientada a dados n\u00e3o \u00e9 apenas uma tend\u00eancia, mas um compromisso com a inova\u00e7\u00e3o e a efici\u00eancia no setor p\u00fablico.</p>"},{"location":"sobre-projeto/overview/","title":"Vis\u00e3o geral","text":"<p>O Gov Hub BR \u00e9 uma iniciativa para enfrentar os desafios da fragmenta\u00e7\u00e3o, redund\u00e2ncia e inconsist\u00eancias nos sistemas estruturantes do governo federal. Seu prop\u00f3sito fundamental \u00e9 transformar dados p\u00fablicos em ativos estrat\u00e9gicos e valiosos, promovendo a efici\u00eancia administrativa, a transpar\u00eancia e a confian\u00e7a p\u00fablica.</p> <p>A iniciativa adota uma abordagem inovadora baseada em evid\u00eancias, integrando dados de diferentes sistemas para apoiar gestores p\u00fablicos na tomada de decis\u00f5es fundamentadas em an\u00e1lises quantitativas e qualitativas. Essa perspectiva reduz a depend\u00eancia de suposi\u00e7\u00f5es, promovendo uma gest\u00e3o mais assertiva e eficaz.</p> <p>Ao eliminar barreiras de comunica\u00e7\u00e3o entre os sistemas estruturantes e garantir interoperabilidade por meio dos dados, o projeto oferece uma vis\u00e3o unificada das informa\u00e7\u00f5es governamentais. A qualifica\u00e7\u00e3o e integra\u00e7\u00e3o de dados n\u00e3o s\u00f3 otimizam processos internos, como tamb\u00e9m fortalecem a transpar\u00eancia e a responsabilidade p\u00fablica, disponibilizando dados organizados tanto para \u00f3rg\u00e3os p\u00fablicos quanto para a sociedade civil.</p>"},{"location":"sobre-projeto/overview/#objetivos","title":"Objetivos","text":"<p>O Gov Hub BR busca automatizar processos e reduzir custos com a implementa\u00e7\u00e3o de solu\u00e7\u00f5es baseadas em software livre que facilitem a coleta, an\u00e1lise e visualiza\u00e7\u00e3o de dados. O uso de tecnologias open source assegura que a infraestrutura seja escal\u00e1vel, flex\u00edvel e sustent\u00e1vel, adaptando-se a novas necessidades e mudan\u00e7as futuras.</p> <p>O projeto tamb\u00e9m visa desenvolver capacidades t\u00e9cnicas e institucionais, oferecendo ferramentas e diretrizes que permitam aos gestores p\u00fablicos explorar o potencial dos dados de forma eficiente e aut\u00f4noma. Para isso, promove uma cultura organizacional voltada para dados, incentivando a alfabetiza\u00e7\u00e3o em dados em todas as esferas governamentais e valorizando pr\u00e1ticas \u00e9ticas, de seguran\u00e7a e de transpar\u00eancia na gest\u00e3o da informa\u00e7\u00e3o.</p> <p>Al\u00e9m disso, ao qualificar os dados integrados, o projeto fortalece a governan\u00e7a p\u00fablica e cria bases s\u00f3lidas para o aprimoramento das pol\u00edticas p\u00fablicas e dos servi\u00e7os oferecidos \u00e0 popula\u00e7\u00e3o.</p>"},{"location":"sobre-projeto/overview/#impactos-esperados","title":"Impactos esperados","text":"<p>A qualifica\u00e7\u00e3o e integra\u00e7\u00e3o dos dados contribuem diretamente para a redu\u00e7\u00e3o da fragmenta\u00e7\u00e3o e das inconsist\u00eancias nos sistemas estruturantes, permitindo que decis\u00f5es sejam baseadas em informa\u00e7\u00f5es concretas e atualizadas. Isso gera um aumento da efici\u00eancia administrativa, otimiza o uso de recursos p\u00fablicos e promove maior agilidade na entrega de servi\u00e7os governamentais.</p> <p>Al\u00e9m disso, o fortalecimento da transpar\u00eancia e do controle social, por meio da disponibiliza\u00e7\u00e3o de dados organizados e acess\u00edveis, amplia a capacidade de auditoria, fortalece a confian\u00e7a entre governo e sociedade e contribui para uma gest\u00e3o p\u00fablica mais aberta, respons\u00e1vel e confi\u00e1vel.</p>"},{"location":"sobre-projeto/overview/#tecnologias-utilizadas","title":"Tecnologias utilizadas","text":"<p>O projeto adota um stack tecnol\u00f3gico baseado em solu\u00e7\u00f5es open-source, incluindo Apache Airflow para orquestra\u00e7\u00e3o de pipelines de dados, DBT para transforma\u00e7\u00e3o e modelagem de informa\u00e7\u00f5es, Apache Superset para visualiza\u00e7\u00e3o e explora\u00e7\u00e3o, PostgreSQL como banco de dados relacional e Docker para containeriza\u00e7\u00e3o e implanta\u00e7\u00e3o. A escolha dessas tecnologias permite maior flexibilidade, escalabilidade e integra\u00e7\u00e3o com diferentes sistemas governamentais.  </p> <ul> <li>Apache Airflow - Orquestra\u00e7\u00e3o de pipelines de dados</li> <li>DBT (Data Build Tool) - Transforma\u00e7\u00e3o e modelagem de dados</li> <li>Apache Superset - Visualiza\u00e7\u00e3o e explora\u00e7\u00e3o de dados</li> <li>PostgreSQL - Banco de dados relacional</li> <li>Docker - Containeriza\u00e7\u00e3o e implanta\u00e7\u00e3o de aplica\u00e7\u00f5es</li> </ul>"},{"location":"sobre-projeto/replicacao/","title":"Replica\u00e7\u00e3o do Gov Hub BR em Outros \u00d3rg\u00e3os","text":"<p>Esta se\u00e7\u00e3o da documenta\u00e7\u00e3o apresenta um guia pr\u00e1tico para replica\u00e7\u00e3o do projeto Gov Hub BR em outros \u00f3rg\u00e3os p\u00fablicos. A proposta \u00e9 compartilhar a arquitetura, os processos e os aprendizados obtidos durante a aplica\u00e7\u00e3o da plataforma no IPEA, com o objetivo de permitir que outros times t\u00e9cnicos possam adaptar e reutilizar a solu\u00e7\u00e3o em seus contextos.</p> <p>A plataforma foi desenvolvida para ser flex\u00edvel, modular e baseada em software livre, com foco na integra\u00e7\u00e3o, qualifica\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados p\u00fablicos estruturantes. Embora a replica\u00e7\u00e3o completa dependa do n\u00edvel de acesso \u00e0s APIs espec\u00edficas de cada \u00f3rg\u00e3o, a estrutura t\u00e9cnica at\u00e9 a camada Silver foi projetada para funcionar de forma gen\u00e9rica.</p> <p>\u26a0\ufe0f Nota importante: Algumas APIs governamentais exigem autentica\u00e7\u00e3o com certificado digital, o que limita o acesso aos dados de determinados \u00f3rg\u00e3os. Essa documenta\u00e7\u00e3o destaca essas limita\u00e7\u00f5es e prop\u00f5e caminhos alternativos.</p>"},{"location":"sobre-projeto/replicacao/#o-que-voce-vai-encontrar-aqui","title":"\ud83e\udded O que voc\u00ea vai encontrar aqui","text":"<p>Esta se\u00e7\u00e3o est\u00e1 dividida em t\u00f3picos que cobrem desde os pr\u00e9-requisitos t\u00e9cnicos at\u00e9 desafios enfrentados e recomenda\u00e7\u00f5es pr\u00e1ticas:</p> <ul> <li> <p>Pr\u00e9-requisitos   Tecnologias, infraestrutura e conhecimentos m\u00ednimos recomendados para iniciar a replica\u00e7\u00e3o.</p> </li> <li> <p>Arquitetura da Solu\u00e7\u00e3o   Vis\u00e3o geral da arquitetura da plataforma, incluindo o fluxo de dados e os componentes utilizados.</p> </li> <li> <p>Processo de Instala\u00e7\u00e3o   Etapas de instala\u00e7\u00e3o e configura\u00e7\u00e3o da plataforma, incluindo o processo de ETL.</p> </li> <li> <p>Dashboards e Templates   Apresenta\u00e7\u00e3o de templates gen\u00e9ricos para a camada Gold e dashboards no Superset.</p> </li> <li> <p>Guia de Contribui\u00e7\u00e3o   Boas pr\u00e1ticas e sugest\u00f5es para facilitar a adapta\u00e7\u00e3o da plataforma em diferentes contextos organizacionais.</p> </li> </ul>"},{"location":"sobre-projeto/replicacao/#publico-alvo","title":"\ud83c\udfaf P\u00fablico-alvo","text":"<p>Este material \u00e9 direcionado a: - Equipes t\u00e9cnicas de \u00f3rg\u00e3os p\u00fablicos que desejam estruturar sua governan\u00e7a de dados. - Profissionais de dados e gestores que buscam entender como implantar uma plataforma integrada com base em dados p\u00fablicos.</p>"},{"location":"sobre-projeto/replicacao/#contribuicoes-e-suporte","title":"\ud83d\udce3 Contribui\u00e7\u00f5es e suporte","text":"<p>Caso queira colaborar com melhorias nesta documenta\u00e7\u00e3o ou tirar d\u00favidas sobre o processo de replica\u00e7\u00e3o, entre em contato com o time do projeto.</p> <p>Essa documenta\u00e7\u00e3o foi desenvolvida com base em um projeto real aplicado no IPEA. Nosso objetivo \u00e9 facilitar o reuso e estimular a cria\u00e7\u00e3o de uma cultura p\u00fablica orientada a dados.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/","title":"Fundamentos e Relev\u00e2ncia","text":"<p>Os sistemas estruturantes s\u00e3o o n\u00facleo operacional do governo federal, projetados para apoiar atividades essenciais de gest\u00e3o e garantir a padroniza\u00e7\u00e3o e efici\u00eancia na administra\u00e7\u00e3o p\u00fablica. Eles desempenham um papel fundamental na consolida\u00e7\u00e3o, integra\u00e7\u00e3o e qualifica\u00e7\u00e3o de dados, tornando-se indispens\u00e1veis para a formula\u00e7\u00e3o e execu\u00e7\u00e3o de pol\u00edticas p\u00fablicas.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#o-que-sao-os-sistemas-estruturantes","title":"O Que S\u00e3o os Sistemas Estruturantes?","text":"<p>Os sistemas estruturantes s\u00e3o plataformas de software gerenciadas por \u00f3rg\u00e3os centrais do governo federal, projetadas para organizar e otimizar as principais opera\u00e7\u00f5es administrativas. Eles servem como ponto de conex\u00e3o entre diversos \u00f3rg\u00e3os governamentais, promovendo interoperabilidade e integridade de dados.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#exemplos-de-sistemas-estruturantes","title":"Exemplos de Sistemas Estruturantes","text":"<ul> <li> <p>SIAFI (Sistema Integrado de Administra\u00e7\u00e3o Financeira):   Respons\u00e1vel pela gest\u00e3o financeira e execu\u00e7\u00e3o or\u00e7ament\u00e1ria do governo federal.</p> </li> <li> <p>SIOP (Sistema Integrado de Planejamento e Or\u00e7amento):   Ferramenta para planejamento or\u00e7ament\u00e1rio, integrando objetivos e metas governamentais.</p> </li> <li> <p>SIAPE (Sistema Integrado de Administra\u00e7\u00e3o de Recursos Humanos):   Utilizado para o gerenciamento de pessoal no \u00e2mbito federal.</p> </li> <li> <p>SIORG (Sistema de Organiza\u00e7\u00e3o e Inova\u00e7\u00e3o Institucional):   Centraliza informa\u00e7\u00f5es sobre a estrutura organizacional dos \u00f3rg\u00e3os governamentais.</p> </li> </ul> <p>Outros exemplos incluem sistemas voltados \u00e0 contabilidade, controle interno, gest\u00e3o de documentos e aquisi\u00e7\u00f5es p\u00fablicas.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#desafios-e-problemas-estruturantes","title":"Desafios e Problemas Estruturantes","text":"<p>Embora os sistemas sejam indispens\u00e1veis, muitos enfrentam desafios hist\u00f3ricos relacionados \u00e0 sua fragmenta\u00e7\u00e3o e falta de integra\u00e7\u00e3o.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#fragmentacao-de-dados","title":"Fragmenta\u00e7\u00e3o de Dados","text":"<ul> <li> <p>Sistemas Legados:   Muitos sistemas estruturantes foram desenvolvidos de forma independente, o que dificulta a comunica\u00e7\u00e3o entre eles.</p> </li> <li> <p>Redund\u00e2ncia e Inconsist\u00eancias:   A aus\u00eancia de interoperabilidade eficiente leva \u00e0 duplica\u00e7\u00e3o de dados e inconsist\u00eancias nas informa\u00e7\u00f5es armazenadas.</p> </li> </ul>"},{"location":"sobre-projeto/sistemas-estruturantes/#impacto-na-gestao-publica","title":"Impacto na Gest\u00e3o P\u00fablica","text":"<ul> <li> <p>Dificuldade na Tomada de Decis\u00e3o:   A fragmenta\u00e7\u00e3o exige que gestores realizem processos manuais de cruzamento de dados, reduzindo a agilidade nas respostas governamentais.</p> </li> <li> <p>Barreiras \u00e0 Transpar\u00eancia:   Dados n\u00e3o integrados dificultam a gera\u00e7\u00e3o de relat\u00f3rios abrangentes, impactando negativamente a presta\u00e7\u00e3o de contas p\u00fablica.</p> </li> </ul>"},{"location":"sobre-projeto/sistemas-estruturantes/#solucoes-e-abordagem-do-projeto","title":"Solu\u00e7\u00f5es e Abordagem do Projeto","text":"<p>O projeto desenvolvido pelo IPEA e Lab Livre visa solucionar os problemas dos sistemas estruturantes atrav\u00e9s de:</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#integracao-e-interoperabilidade","title":"Integra\u00e7\u00e3o e Interoperabilidade","text":"<p>Por meio de APIs bem documentadas e processos automatizados, o projeto promove a comunica\u00e7\u00e3o entre diferentes sistemas estruturantes, eliminando redund\u00e2ncias e inconsist\u00eancias.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#qualificacao-de-dados","title":"Qualifica\u00e7\u00e3o de Dados","text":"<p>Os dados coletados s\u00e3o processados, cruzados e organizados em tabelas otimizadas dentro de um Data Warehouse, criando uma base s\u00f3lida para an\u00e1lises estrat\u00e9gicas.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#visualizacao-e-relatorios-automatizados","title":"Visualiza\u00e7\u00e3o e Relat\u00f3rios Automatizados","text":"<p>Dashboards interativos desenvolvidos com ferramentas como Apache Superset oferecem relat\u00f3rios personaliz\u00e1veis, permitindo uma an\u00e1lise mais acess\u00edvel e estrat\u00e9gica.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#beneficios-para-a-administracao-publica","title":"Benef\u00edcios para a Administra\u00e7\u00e3o P\u00fablica","text":""},{"location":"sobre-projeto/sistemas-estruturantes/#decisoes-baseadas-em-evidencias","title":"Decis\u00f5es Baseadas em Evid\u00eancias","text":"<p>Os sistemas integrados permitem que gestores acessem informa\u00e7\u00f5es precisas e atualizadas, promovendo uma governan\u00e7a mais assertiva.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#eficiencia-operacional","title":"Efici\u00eancia Operacional","text":"<p>A automa\u00e7\u00e3o de processos reduz custos e aumenta a produtividade dos \u00f3rg\u00e3os p\u00fablicos.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#transparencia-e-responsabilidade","title":"Transpar\u00eancia e Responsabilidade","text":"<p>A integra\u00e7\u00e3o de dados facilita a publica\u00e7\u00e3o de relat\u00f3rios consistentes e compreens\u00edveis, promovendo maior confian\u00e7a entre governo e sociedade.</p>"},{"location":"sobre-projeto/sistemas-estruturantes/#futuro-dos-sistemas-estruturantes","title":"Futuro dos Sistemas Estruturantes","text":"<p>Com a ado\u00e7\u00e3o de tecnologias emergentes e pr\u00e1ticas inovadoras, o projeto estabelece um modelo replic\u00e1vel e escal\u00e1vel para outros contextos. As melhorias cont\u00ednuas nos sistemas estruturantes ir\u00e3o fortalecer ainda mais a administra\u00e7\u00e3o p\u00fablica, garantindo que os dados se tornem verdadeiros ativos estrat\u00e9gicos.</p>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/plataforma/","title":"Plataforma","text":""},{"location":"blog/category/dados-p%C3%BAblicos/","title":"Dados P\u00fablicos","text":""},{"location":"blog/category/tutorial/","title":"Tutorial","text":""},{"location":"blog/category/dbt/","title":"DBT","text":""},{"location":"blog/category/infraestrutura/","title":"Infraestrutura","text":""},{"location":"blog/category/superset/","title":"Superset","text":""},{"location":"blog/category/dashboards/","title":"Dashboards","text":""},{"location":"blog/category/visualiza%C3%A7%C3%A3o/","title":"Visualiza\u00e7\u00e3o","text":""}]}